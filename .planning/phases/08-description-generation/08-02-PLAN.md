---
phase: 08-description-generation
plan: 02
type: execute
wave: 2
depends_on: ["08-01"]
files_modified:
  - src/jobforge/description/prompts.py
  - src/jobforge/description/service.py
  - src/jobforge/description/__init__.py
  - tests/test_description_service.py
autonomous: true

must_haves:
  truths:
    - "User can generate description for job title showing lead statement from L6 level"
    - "User can generate descriptions for job families and functions"
    - "Each description has provenance indicating source (authoritative vs LLM)"
    - "LLM descriptions use NOC boundary words as context constraints"
  artifacts:
    - path: "src/jobforge/description/prompts.py"
      provides: "System prompt and prompt builder for NOC-style descriptions"
      exports: ["DESCRIPTION_SYSTEM_PROMPT", "build_description_prompt"]
    - path: "src/jobforge/description/service.py"
      provides: "DescriptionGenerationService with generate methods"
      exports: ["DescriptionGenerationService", "generate_description"]
    - path: "tests/test_description_service.py"
      provides: "Service tests including mocked LLM calls"
      min_lines: 100
  key_links:
    - from: "src/jobforge/description/service.py"
      to: "src/jobforge/imputation/resolution.py"
      via: "resolve_job_title import"
      pattern: "from jobforge\\.imputation\\.resolution import resolve_job_title"
    - from: "src/jobforge/description/service.py"
      to: "src/jobforge/external/llm/client.py"
      via: "LLMClient import"
      pattern: "from jobforge\\.external\\.llm import LLMClient"
    - from: "src/jobforge/description/service.py"
      to: "src/jobforge/description/sources.py"
      via: "get_lead_statement_for_oasis call"
      pattern: "get_lead_statement_for_oasis"
---

<objective>
Create DescriptionGenerationService that orchestrates the source cascade and generates descriptions for job titles, families, and functions with full provenance.

Purpose: Complete Phase 8 requirements IMP-05 (description generation) and IMP-06 (multiple sources with provenance). The service uses existing resolution infrastructure and LLM client while adding description-specific prompting.

Output: Working `DescriptionGenerationService` with NOC-style prompts and comprehensive test coverage.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/08-description-generation/08-CONTEXT.md
@.planning/phases/08-description-generation/08-RESEARCH.md

# Prior plan output (must exist)
@.planning/phases/08-description-generation/08-01-SUMMARY.md

# Existing infrastructure to reuse
@src/jobforge/imputation/resolution.py
@src/jobforge/external/llm/client.py
@src/jobforge/external/llm/prompts.py
@src/jobforge/external/llm/service.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create description prompts</name>
  <files>src/jobforge/description/prompts.py</files>
  <action>
Create prompt templates for NOC-style description generation.

**prompts.py:**

1. Create system prompt for description generation:
   ```python
   DESCRIPTION_SYSTEM_PROMPT = """You are generating occupational descriptions for a Canadian workforce classification system.

   Guidelines:
   - Use formal, third-person voice matching NOC (National Occupational Classification) style
   - Start descriptions with the occupation/entity name (e.g., "Software engineers design...")
   - Focus on typical duties, responsibilities, and characteristics
   - Keep descriptions between 2-4 sentences
   - Use NOC-aligned terminology provided in the context
   - Do NOT use "you", "your", or "this role involves" phrasing

   Your descriptions will supplement authoritative Canadian occupational data where none exists."""
   ```

2. Create user prompt builder for job titles:
   ```python
   def build_title_description_prompt(
       job_title: str,
       job_family: str | None,
       job_function: str | None,
       unit_group_title: str | None,
       unit_group_definition: str | None,
       labels: list[str] | None = None,
   ) -> str:
       """Build prompt for job title description.

       Includes NOC context as "boundary words" per CONTEXT.md.

       Args:
           job_title: The job title to describe
           job_family: Job family context
           job_function: Job function context
           unit_group_title: NOC Unit Group title (L5 context)
           unit_group_definition: NOC Unit Group definition
           labels: List of L6 labels in the Unit Group

       Returns:
           Formatted prompt string.
       """
       # Build context section with available NOC info
       # Include boundary words from NOC vocabulary
       # Request NOC-style description
   ```

3. Create user prompt builder for families/functions:
   ```python
   def build_aggregate_description_prompt(
       entity_name: str,
       entity_type: Literal["family", "function"],
       member_titles: list[str],
       noc_context: str | None = None,
   ) -> str:
       """Build prompt for job family or function description.

       Uses member job titles as context for describing the aggregate entity.

       Args:
           entity_name: Name of the family or function
           entity_type: "family" or "function"
           member_titles: Sample job titles that belong to this entity
           noc_context: Additional NOC context if available

       Returns:
           Formatted prompt string.
       """
   ```

4. Create LLM response model for descriptions:
   ```python
   class DescriptionResponse(BaseModel):
       """LLM response for description generation."""
       description: str = Field(
           description="Generated occupational description in NOC style"
       )
       confidence: float = Field(
           ge=0.0, le=1.0,
           description="LLM's confidence in this description (0.0-1.0)"
       )
       context_used: str = Field(
           description="Summary of NOC context that influenced the description"
       )
   ```

Follow existing patterns from `jobforge.external.llm.prompts` for prompt structure.
  </action>
  <verify>
```bash
python -c "from jobforge.description.prompts import DESCRIPTION_SYSTEM_PROMPT, build_title_description_prompt, build_aggregate_description_prompt, DescriptionResponse; print('Prompts import OK')"
python -c "from jobforge.description.prompts import build_title_description_prompt; p = build_title_description_prompt('Data Analyst', 'Analytics', 'IT', 'Data scientists', None); print(p[:200])"
```
  </verify>
  <done>
DESCRIPTION_SYSTEM_PROMPT enforces NOC formal voice, build_title_description_prompt includes all NOC boundary words, build_aggregate_description_prompt handles family/function aggregation, DescriptionResponse model works with Structured Outputs.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create DescriptionGenerationService</name>
  <files>
    src/jobforge/description/service.py
    src/jobforge/description/__init__.py
  </files>
  <action>
Create the main service class that orchestrates description generation.

**service.py:**

1. Create DescriptionGenerationService class:
   ```python
   class DescriptionGenerationService:
       """Service for generating descriptions with source cascade and provenance.

       Orchestrates the description generation process:
       1. Resolve job title to OASIS profile code (for titles)
       2. Check for authoritative lead statement
       3. If no authoritative source, generate with LLM
       4. Return description with full provenance

       Attributes:
           llm_client: LLMClient instance for LLM fallback.
           gold_path: Path to gold layer data.

       Example:
           >>> service = DescriptionGenerationService()
           >>> result = service.generate_title_description(
           ...     job_title="Data Analyst",
           ...     unit_group_id="21211",
           ... )
           >>> print(f"{result.description} (source: {result.provenance.source_type})")
       """

       def __init__(
           self,
           llm_client: LLMClient | None = None,
           gold_path: Path | None = None,
       ):
           """Initialize the service."""
   ```

2. Implement job title description generation:
   ```python
   def generate_title_description(
       self,
       job_title: str,
       unit_group_id: str,
       job_family: str | None = None,
       job_function: str | None = None,
   ) -> GeneratedDescription:
       """Generate description for a job title.

       Source cascade per CONTEXT.md:
       1. Resolve job title to OASIS profile using existing resolution
       2. If resolved, look up authoritative lead statement
       3. If no lead statement, generate with LLM using NOC context

       Args:
           job_title: The job title to describe
           unit_group_id: The 5-digit NOC Unit Group ID
           job_family: Optional job family context
           job_function: Optional job function context

       Returns:
           GeneratedDescription with full provenance.
       """
       # Use resolve_job_title from resolution.py
       # Use get_lead_statement_for_oasis from sources.py
       # Fall back to LLM with boundary words
   ```

3. Implement family description generation:
   ```python
   def generate_family_description(
       self,
       family_name: str,
       member_titles: list[str] | None = None,
   ) -> GeneratedDescription:
       """Generate description for a job family.

       Per CONTEXT.md, families are at L5 level. Uses LLM with
       member job titles as context since there's no direct
       authoritative source for family descriptions.

       Args:
           family_name: Name of the job family
           member_titles: Sample job titles in this family

       Returns:
           GeneratedDescription with LLM source provenance.
       """
   ```

4. Implement function description generation:
   ```python
   def generate_function_description(
       self,
       function_name: str,
       member_titles: list[str] | None = None,
   ) -> GeneratedDescription:
       """Generate description for a job function.

       Per CONTEXT.md, functions are at L4 level. Uses LLM with
       member job titles as context.

       Args:
           function_name: Name of the job function
           member_titles: Sample job titles in this function

       Returns:
           GeneratedDescription with LLM source provenance.
       """
   ```

5. Create convenience function:
   ```python
   def generate_description(
       entity_type: Literal["title", "family", "function"],
       entity_name: str,
       **kwargs,
   ) -> GeneratedDescription:
       """Convenience function for single description generation.

       Creates a one-off DescriptionGenerationService instance.
       """
   ```

**Update __init__.py:**
Add exports: DescriptionGenerationService, generate_description, DescriptionResponse, DESCRIPTION_SYSTEM_PROMPT, build_title_description_prompt, build_aggregate_description_prompt
  </action>
  <verify>
```bash
python -c "from jobforge.description import DescriptionGenerationService, generate_description; print('Service import OK')"
python -c "
from jobforge.description import DescriptionGenerationService
from jobforge.external.llm import LLMClient

# Test service instantiation (without API key - should still create)
service = DescriptionGenerationService()
print(f'Service created with gold_path: {service.gold_path}')
"
```
  </verify>
  <done>
DescriptionGenerationService instantiates correctly, generate_title_description uses resolution + lead statement lookup with LLM fallback, generate_family_description and generate_function_description use LLM with context, all return GeneratedDescription with appropriate provenance.
  </done>
</task>

<task type="auto">
  <name>Task 3: Add service tests</name>
  <files>tests/test_description_service.py</files>
  <action>
Create comprehensive tests for the description generation service.

**test_description_service.py:**

Prompt Tests:
1. Test DESCRIPTION_SYSTEM_PROMPT contains NOC style guidance
2. Test DESCRIPTION_SYSTEM_PROMPT prohibits "you"/"your" phrasing
3. Test build_title_description_prompt includes job title
4. Test build_title_description_prompt includes NOC context when provided
5. Test build_title_description_prompt handles missing optional fields
6. Test build_aggregate_description_prompt for family type
7. Test build_aggregate_description_prompt for function type
8. Test build_aggregate_description_prompt includes member titles
9. Test DescriptionResponse model parsing
10. Test DescriptionResponse confidence bounds

Service Tests (with mocked LLM):
11. Test service instantiation with default settings
12. Test service instantiation with custom gold_path
13. Test generate_title_description returns AUTHORITATIVE when lead statement exists
14. Test generate_title_description returns LLM when no lead statement
15. Test generate_title_description uses resolution to find OASIS code
16. Test generate_title_description includes NOC boundary words in LLM prompt
17. Test generate_family_description returns LLM source
18. Test generate_family_description includes member titles in prompt
19. Test generate_function_description returns LLM source
20. Test generate_description convenience function routes correctly

Provenance Tests:
21. Test AUTHORITATIVE description has confidence from resolution
22. Test LLM description has confidence from LLM response
23. Test AUTHORITATIVE description has resolution_method populated
24. Test LLM description has model_version populated
25. Test all descriptions have timestamp

Use pytest fixtures and unittest.mock.patch for LLM client mocking. Follow patterns from tests/test_llm_imputation.py.
  </action>
  <verify>
```bash
pytest tests/test_description_service.py -v
pytest tests/ -v --tb=short
```
  </verify>
  <done>
All prompt tests pass (system prompt content, prompt builder behavior, response model), all service tests pass (instantiation, title/family/function generation, source cascade), all provenance tests pass (confidence, resolution_method, model_version, timestamp), full test suite remains green.
  </done>
</task>

</tasks>

<verification>
After all tasks complete:

1. Full package imports:
```bash
python -c "
from jobforge.description import (
    DescriptionSource, DescriptionProvenance, GeneratedDescription,
    DescriptionGenerationService, generate_description,
    DESCRIPTION_SYSTEM_PROMPT, build_title_description_prompt,
    load_lead_statements, get_lead_statement_for_oasis, determine_source_type,
)
print('All exports available')
"
```

2. Test authoritative path (no API key needed):
```bash
python -c "
from jobforge.description import DescriptionGenerationService, DescriptionSource

service = DescriptionGenerationService()

# Test with a known OASIS code that has lead statement
# This should return AUTHORITATIVE without calling LLM
from jobforge.imputation.resolution import resolve_job_title
resolution = resolve_job_title('Administrative officers', '13100')
if resolution:
    from jobforge.description.sources import get_lead_statement_for_oasis
    lead = get_lead_statement_for_oasis(resolution.source_identifier)
    if lead:
        print(f'Lead statement found: {lead[:100]}...')
        print('AUTHORITATIVE path verified')
"
```

3. Verify LLM prompt contains boundary words:
```bash
python -c "
from jobforge.description.prompts import build_title_description_prompt

prompt = build_title_description_prompt(
    job_title='Data Analyst',
    job_family='Analytics',
    job_function='Information Technology',
    unit_group_title='Data scientists',
    unit_group_definition='Data scientists develop and implement methods...',
    labels=['Data scientists', 'Data analysts'],
)
assert 'Data scientists' in prompt, 'NOC boundary words missing'
assert 'Analytics' in prompt, 'Job family context missing'
print('Boundary words verified in prompt')
"
```

4. Full test suite:
```bash
pytest tests/ -v --tb=short
```
</verification>

<success_criteria>
- [ ] DESCRIPTION_SYSTEM_PROMPT enforces NOC formal third-person voice
- [ ] build_title_description_prompt includes NOC boundary words (unit group, labels)
- [ ] build_aggregate_description_prompt handles family/function with member titles
- [ ] DescriptionGenerationService.generate_title_description uses resolution + lead statement first
- [ ] DescriptionGenerationService.generate_title_description falls back to LLM with context
- [ ] DescriptionGenerationService.generate_family_description uses LLM with member titles
- [ ] DescriptionGenerationService.generate_function_description uses LLM with member titles
- [ ] All descriptions have full provenance (source_type, confidence, timestamp)
- [ ] AUTHORITATIVE descriptions have resolution_method, matched_text
- [ ] LLM descriptions have model_version, input_context
- [ ] All new tests pass
- [ ] Full test suite remains green (target ~250+ tests)
</success_criteria>

<output>
After completion, create `.planning/phases/08-description-generation/08-02-SUMMARY.md`
</output>
