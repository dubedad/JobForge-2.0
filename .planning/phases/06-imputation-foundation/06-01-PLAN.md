---
phase: 06-imputation-foundation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/jobforge/imputation/__init__.py
  - src/jobforge/imputation/models.py
  - src/jobforge/imputation/resolution.py
  - tests/test_noc_resolution.py
autonomous: true

must_haves:
  truths:
    - "Job title with known NOC resolves to correct hierarchy level"
    - "Resolution method returns correct confidence score (1.00, 0.95, 0.85, 0.60, 0.40)"
    - "Single-label UG optimization works (68% of cases)"
    - "Fuzzy matching returns best L6 label when exact match unavailable"
  artifacts:
    - path: "src/jobforge/imputation/models.py"
      provides: "Pydantic schemas for resolution results"
      contains: "ResolutionMethodEnum"
      exports: ["ResolutionMethodEnum", "ProvenanceEnum", "NOCResolutionResult", "ImputedValue"]
    - path: "src/jobforge/imputation/resolution.py"
      provides: "NOC resolution service"
      contains: "resolve_job_title"
      exports: ["resolve_job_title", "build_resolution_context", "ResolutionContext"]
    - path: "tests/test_noc_resolution.py"
      provides: "Validation tests for resolution algorithm"
      contains: "test_single_label"
      min_lines: 100
  key_links:
    - from: "src/jobforge/imputation/resolution.py"
      to: "data/gold/element_labels.parquet"
      via: "pl.scan_parquet"
      pattern: "scan_parquet.*element_labels"
    - from: "src/jobforge/imputation/resolution.py"
      to: "data/gold/element_example_titles.parquet"
      via: "pl.scan_parquet"
      pattern: "scan_parquet.*example_titles"
---

<objective>
Port NOC resolution service from prototype to v2.0 with validation tests

Purpose: Establish the core resolution algorithm that determines how job titles map to NOC hierarchy levels (L5/L6/L7) with confidence scoring. This is the foundation for all imputation logic.

Output: Working resolution service that passes validation tests against known prototype outputs.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/06-imputation-foundation/06-CONTEXT.md
@.planning/phases/06-imputation-foundation/06-RESEARCH.md
@src/jobforge/pipeline/provenance.py
@src/jobforge/ingestion/element.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create imputation models module</name>
  <files>
    src/jobforge/imputation/__init__.py
    src/jobforge/imputation/models.py
  </files>
  <action>
Create new `src/jobforge/imputation/` package with Pydantic schemas ported from prototype.

In `models.py`, create:
1. `ResolutionMethodEnum` - Enum with 5 resolution methods and their confidence scores:
   - DIRECT_MATCH (1.00) - L6 Label exact match
   - EXAMPLE_MATCH (0.95) - L7 Example Title match
   - UG_DOMINANT (0.85) - Single-label Unit Group
   - LABEL_IMPUTATION (0.60) - Best-match fuzzy label
   - UG_IMPUTATION (0.40) - Fallback to UG context

2. `ProvenanceEnum` - Enum for tracking value provenance:
   - NATIVE - Value exists at this level
   - INHERITED - Value inherited from parent
   - IMPUTED - Value generated externally

3. `NOCResolutionResult` - Pydantic model with:
   - noc_level_used: Literal[5, 6, 7]
   - resolution_method: ResolutionMethodEnum
   - confidence_score: float (0.0-1.0)
   - source_identifier: str (OASIS code or unit_group_id)
   - matched_text: str | None
   - rationale: str
   - resolved_at: datetime

4. `ImputedValue` - Pydantic model for single imputed value:
   - value: str
   - source_level: Literal[5, 6, 7]
   - source_identifier: str
   - provenance: ProvenanceEnum
   - confidence: float
   - imputed_at: datetime

In `__init__.py`, export all public models.

Follow existing codebase patterns from `src/jobforge/pipeline/models.py` for Pydantic 2 style.
  </action>
  <verify>
Run `python -c "from jobforge.imputation.models import ResolutionMethodEnum, NOCResolutionResult; print('OK')"` succeeds
  </verify>
  <done>
All 4 model classes importable from jobforge.imputation.models with correct field types
  </done>
</task>

<task type="auto">
  <name>Task 2: Port NOC resolution service</name>
  <files>
    src/jobforge/imputation/resolution.py
  </files>
  <action>
Port resolution logic from prototype `noc_resolution_service.py` to pure Python operating on Polars DataFrames.

Create `resolution.py` with:

1. Internal dataclasses (NOT Pydantic - internal only):
   - `L6Label` - oasis_profile_code, unit_group_id, label, lead_statement
   - `L7ExampleTitle` - element_text, oasis_profile_code, unit_group_id
   - `ResolutionContext` - unit_group_id, unit_group_title, unit_group_definition, labels list, example_titles_by_oasis dict, label_count, is_single_label
   - `BestMatchResult` - label, similarity_score, matched_via

2. Confidence constants:
   - CONFIDENCE_DIRECT_MATCH = 1.00
   - CONFIDENCE_EXAMPLE_MATCH = 0.95
   - CONFIDENCE_UG_DOMINANT = 0.85
   - CONFIDENCE_LABEL_IMPUTATION = 0.60
   - CONFIDENCE_UG_IMPUTATION = 0.40
   - FUZZY_GOOD_MATCH_THRESHOLD = 70

3. Index building functions with @lru_cache(maxsize=1):
   - `_build_labels_by_unit_group(gold_path: Path)` - Load element_labels.parquet, group by unit_group_id
   - `_build_example_titles_by_oasis(gold_path: Path)` - Load element_example_titles.parquet, group by oasis_profile_code
   - `_load_noc_structure(gold_path: Path)` - Load dim_noc.parquet for unit group titles/definitions

4. Resolution context builder:
   - `build_resolution_context(unit_group_id: str, gold_path: Path)` - Combines L5/L6/L7 data for a unit group

5. Core resolution function:
   - `resolve_job_title(job_title: str, unit_group_id: str, gold_path: Path) -> NOCResolutionResult | None`

   Algorithm (from prototype):
   a. Get resolution context; return None if not found
   b. If single-label UG: return UG_DOMINANT immediately (0.85)
   c. Try direct L6 match (case-insensitive): return DIRECT_MATCH (1.00)
   d. Try L7 example title match: return EXAMPLE_MATCH (0.95)
   e. Try fuzzy match against L6 labels using rapidfuzz.fuzz.WRatio:
      - If score >= 70: return LABEL_IMPUTATION (0.60)
      - Else: return UG_IMPUTATION (0.40)

6. Cache clearing utility:
   - `clear_resolution_cache()` - Clears all lru_cache instances

Use `rapidfuzz.fuzz.WRatio` for fuzzy matching (already in prototype). Add rapidfuzz to pyproject.toml dependencies.

CRITICAL: Use Path parameter for gold_path to enable testing with temp directories. Default to `PipelineConfig().gold_path()` if not provided.
  </action>
  <verify>
Run `python -c "from jobforge.imputation.resolution import resolve_job_title; print('OK')"` succeeds
  </verify>
  <done>
Resolution service loads gold data and resolves job titles through NOC hierarchy with correct confidence scores
  </done>
</task>

<task type="auto">
  <name>Task 3: Create validation tests</name>
  <files>
    tests/test_noc_resolution.py
  </files>
  <action>
Create comprehensive test suite for NOC resolution service. Tests validate against known behaviors from prototype.

Test file structure:

1. Fixtures:
   - `gold_path` - Uses existing gold data at `data/gold/`
   - `resolution_context_single_label` - A known single-label UG (check dim_noc for one)
   - `resolution_context_multi_label` - A known multi-label UG

2. Test cases for resolution methods:
   - `test_single_label_ug_returns_ug_dominant()` - Confidence 0.85
   - `test_direct_label_match_returns_direct_match()` - Confidence 1.00
   - `test_example_title_match_returns_example_match()` - Confidence 0.95
   - `test_fuzzy_match_returns_label_imputation()` - Confidence 0.60
   - `test_no_match_returns_ug_imputation()` - Confidence 0.40

3. Edge case tests:
   - `test_invalid_unit_group_returns_none()` - Unknown UG ID
   - `test_empty_job_title_returns_none()` - Empty string input
   - `test_resolution_context_has_labels()` - Context loads L6 data correctly
   - `test_resolution_context_has_example_titles()` - Context loads L7 data correctly

4. Integration tests:
   - `test_batch_resolution()` - Resolve multiple job titles from job_architecture
   - `test_resolution_provenance_fields()` - All required fields populated

Use pytest fixtures with scope="module" for expensive data loading.

IMPORTANT: To find test data, first read a few rows from gold tables to identify actual unit_group_ids and labels:
- element_labels.parquet - contains L6 labels
- element_example_titles.parquet - contains L7 example titles
- job_architecture.parquet - contains job titles with unit_group_id
  </action>
  <verify>
Run `pytest tests/test_noc_resolution.py -v` - all tests pass
  </verify>
  <done>
Test suite validates all 5 resolution methods and edge cases pass
  </done>
</task>

</tasks>

<verification>
1. All imports work: `python -c "from jobforge.imputation import resolution, models; print('OK')"`
2. Resolution service connects to gold data: Load element_labels, element_example_titles
3. Test suite passes: `pytest tests/test_noc_resolution.py -v`
4. Confidence scores match prototype: 1.00, 0.95, 0.85, 0.60, 0.40
</verification>

<success_criteria>
- [ ] Pydantic models match prototype schemas (ResolutionMethodEnum, NOCResolutionResult, etc.)
- [ ] Resolution service loads gold data and builds indexes correctly
- [ ] Single-label UG optimization returns UG_DOMINANT (0.85) - covers 68% of cases
- [ ] All 5 resolution methods return correct confidence scores
- [ ] Test suite validates against known outputs from prototype behavior
- [ ] rapidfuzz dependency added to pyproject.toml
</success_criteria>

<output>
After completion, create `.planning/phases/06-imputation-foundation/06-01-SUMMARY.md`
</output>
