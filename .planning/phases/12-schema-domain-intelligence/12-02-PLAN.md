---
phase: 12-schema-domain-intelligence
plan: 02
type: execute
wave: 2
depends_on: ["12-01"]
files_modified:
  - src/jobforge/api/schema_ddl.py
  - tests/test_schema_ddl.py
autonomous: true

must_haves:
  truths:
    - "DDL output includes COMMENT clauses for columns with descriptions"
    - "DDL includes table-level comments with workforce_dynamic for COPS tables"
    - "DDL includes relationship hints section showing FK joins"
    - "Year columns are quoted in DDL (\"2025\" not 2025)"
  artifacts:
    - path: "src/jobforge/api/schema_ddl.py"
      provides: "Enhanced DDL generator"
      contains: "COMMENT"
    - path: "tests/test_schema_ddl.py"
      provides: "DDL generation tests"
      min_lines: 40
  key_links:
    - from: "src/jobforge/api/schema_ddl.py"
      to: "data/catalog/tables/*.json"
      via: "reads enriched catalog"
      pattern: "json.load"
---

<objective>
Enhance DDL generator to produce semantically rich CREATE TABLE statements

Purpose: Provide Claude with contextual DDL that improves text-to-SQL accuracy
Output: `generate_schema_ddl()` produces DDL with comments, relationship hints, and workforce domain context
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/12-schema-domain-intelligence/12-CONTEXT.md
@.planning/phases/12-schema-domain-intelligence/12-RESEARCH.md
@.planning/phases/12-schema-domain-intelligence/12-01-SUMMARY.md
@src/jobforge/api/schema_ddl.py
@src/jobforge/pipeline/config.py
@data/catalog/tables/cops_employment.json
@data/catalog/schemas/wiq_schema.json
</context>

<tasks>

<task type="auto">
  <name>Task 1: Enhance generate_schema_ddl to use catalog metadata</name>
  <files>src/jobforge/api/schema_ddl.py</files>
  <action>
Modify `src/jobforge/api/schema_ddl.py` to generate enriched DDL:

1. Add helper function `_load_catalog_metadata(config: PipelineConfig) -> dict[str, dict]`:
   - Load all JSON files from `config.catalog_tables_path()` (add method to PipelineConfig if needed: returns `Path("data/catalog/tables")`)
   - Return dict mapping table_name -> full metadata dict
   - Handle missing catalog gracefully (return empty dict)

2. Add helper function `_load_schema_relationships(config: PipelineConfig) -> list[dict]`:
   - Load `data/catalog/schemas/wiq_schema.json`
   - Extract foreign key relationships: list of {from_table, from_column, to_table, to_column}
   - Handle missing schema gracefully (return empty list)

3. Add helper function `_quote_column_name(name: str) -> str`:
   - If name is numeric (e.g., "2023", "2024"), return `"{name}"`
   - Otherwise return name as-is

4. Modify `generate_schema_ddl()`:
   - Load catalog metadata using helper
   - Load relationships using helper
   - For each parquet file:
     a. Get table metadata from catalog (if available)
     b. Build column definitions with COMMENT if description exists and is not generic:
        ```python
        col_name = _quote_column_name(col[0])
        col_type = col[1]
        desc = metadata.get("columns", {}).get(col[0], {}).get("description", "")
        if desc and "Column of type" not in desc:
            col_def = f"  {col_name} {col_type} COMMENT '{desc}'"
        else:
            col_def = f"  {col_name} {col_type}"
        ```
     c. Build CREATE TABLE statement
     d. Add table-level comment with description if available:
        `-- Table: {description}`
     e. Add workforce_dynamic comment if present:
        `-- Workforce dynamic: {workforce_dynamic}`
     f. Add source comment:
        `-- Source: {domain} domain`

5. After all tables, add RELATIONSHIPS section:
   ```sql
   -- RELATIONSHIPS:
   -- cops_employment.unit_group_id -> dim_noc.unit_group_id
   -- cops_employment_growth.unit_group_id -> dim_noc.unit_group_id
   -- ...
   ```

6. Add WORKFORCE INTELLIGENCE section at end:
   ```sql
   -- WORKFORCE INTELLIGENCE:
   -- demand tables: cops_employment, cops_employment_growth, cops_retirements, cops_retirement_rates, cops_other_replacement
   -- supply tables: cops_immigration, cops_school_leavers, cops_other_seekers
   -- Workforce Gap = SUM(job_openings) - SUM(job_seekers_total)
   -- For year columns, use quoted names: SELECT "2025" FROM cops_employment
   ```

Keep backward compatibility: if no catalog exists, fall back to current behavior.
  </action>
  <verify>
    python -c "from jobforge.api.schema_ddl import generate_schema_ddl; ddl=generate_schema_ddl(); print('COMMENT' in ddl, 'RELATIONSHIPS' in ddl, 'workforce' in ddl.lower())"
  </verify>
  <done>
    - DDL contains COMMENT clauses for enriched columns
    - DDL contains RELATIONSHIPS section
    - DDL contains WORKFORCE INTELLIGENCE section
    - Year columns are quoted (\"2025\")
  </done>
</task>

<task type="auto">
  <name>Task 2: Add catalog_tables_path to PipelineConfig</name>
  <files>src/jobforge/pipeline/config.py</files>
  <action>
Check if `catalog_tables_path()` method exists in PipelineConfig. If not, add:

```python
def catalog_tables_path(self) -> Path:
    """Get path to catalog table metadata files."""
    return Path("data/catalog/tables")

def catalog_schemas_path(self) -> Path:
    """Get path to catalog schema files."""
    return Path("data/catalog/schemas")
```

These should return paths relative to project root (consistent with other path methods).
  </action>
  <verify>
    python -c "from jobforge.pipeline.config import PipelineConfig; c=PipelineConfig(); print(c.catalog_tables_path(), c.catalog_schemas_path())"
  </verify>
  <done>
    PipelineConfig has catalog_tables_path() and catalog_schemas_path() methods
  </done>
</task>

<task type="auto">
  <name>Task 3: Add DDL generation tests</name>
  <files>tests/test_schema_ddl.py</files>
  <action>
Create or update `tests/test_schema_ddl.py` with tests:

1. `test_generate_schema_ddl_includes_comments()`:
   - Call `generate_schema_ddl()`
   - Assert "COMMENT" appears in output (requires enriched catalog from 12-01)
   - Assert at least one column has a COMMENT clause

2. `test_generate_schema_ddl_includes_relationships()`:
   - Call `generate_schema_ddl()`
   - Assert "RELATIONSHIPS" appears in output
   - Assert "dim_noc.unit_group_id" appears in relationships section

3. `test_generate_schema_ddl_includes_workforce_hints()`:
   - Call `generate_schema_ddl()`
   - Assert "WORKFORCE INTELLIGENCE" or "demand tables" appears
   - Assert "supply tables" appears

4. `test_generate_schema_ddl_quotes_year_columns()`:
   - Call `generate_schema_ddl()`
   - Assert '"2023"' or '"2025"' appears (quoted year columns)

5. `test_generate_schema_ddl_handles_missing_catalog()`:
   - Create config pointing to non-existent catalog path
   - Call `generate_schema_ddl(config)`
   - Assert returns valid DDL (fallback behavior)
   - Assert "CREATE TABLE" appears

Use pytest. Import from `jobforge.api.schema_ddl`.
  </action>
  <verify>
    pytest tests/test_schema_ddl.py -v
  </verify>
  <done>
    All DDL tests pass, covering comments, relationships, workforce hints, and fallback
  </done>
</task>

</tasks>

<verification>
After all tasks:

1. Generate DDL and inspect:
   ```
   python -c "from jobforge.api.schema_ddl import generate_schema_ddl; print(generate_schema_ddl()[:3000])"
   ```
   Should show COMMENT clauses on columns.

2. Check for relationship section:
   ```
   python -c "from jobforge.api.schema_ddl import generate_schema_ddl; ddl=generate_schema_ddl(); print(ddl[ddl.find('RELATIONSHIPS'):ddl.find('RELATIONSHIPS')+500])"
   ```

3. Run all tests:
   ```
   pytest tests/test_schema_ddl.py -v
   ```
</verification>

<success_criteria>
- [ ] `generate_schema_ddl()` produces DDL with COMMENT clauses
- [ ] Year columns are quoted in DDL output
- [ ] DDL includes RELATIONSHIPS section with FK mappings
- [ ] DDL includes WORKFORCE INTELLIGENCE section with demand/supply hints
- [ ] Fallback to basic DDL when catalog unavailable
- [ ] All tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/12-schema-domain-intelligence/12-02-SUMMARY.md`
</output>
