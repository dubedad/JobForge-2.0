---
phase: 14-og-core
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/jobforge/external/tbs/models.py
  - src/jobforge/external/tbs/parser.py
  - src/jobforge/external/tbs/scraper.py
  - src/jobforge/external/tbs/link_fetcher.py
  - data/tbs/og_subgroups_en.json
  - data/tbs/og_definitions_en.json
  - tests/external/tbs/test_og_scraper.py
autonomous: true

must_haves:
  truths:
    - "Scraper extracts all 65 occupational groups with codes and names"
    - "Scraper follows embedded links to fetch subgroup definitions"
    - "Scraper captures ~200 subgroups linked to parent groups"
    - "All scraped data has provenance (source URL, scraped_at timestamp)"
  artifacts:
    - path: "src/jobforge/external/tbs/models.py"
      provides: "OGRow, OGSubgroup, OGDefinition Pydantic models"
      contains: "class OGSubgroup"
    - path: "src/jobforge/external/tbs/parser.py"
      provides: "Subgroup parsing from TBS table rows"
      contains: "def parse_og_subgroups"
    - path: "data/tbs/og_subgroups_en.json"
      provides: "Scraped subgroup data with provenance"
    - path: "data/tbs/og_definitions_en.json"
      provides: "Fetched OG definitions from linked pages"
  key_links:
    - from: "src/jobforge/external/tbs/scraper.py"
      to: "src/jobforge/external/tbs/parser.py"
      via: "parse_og_subgroups function call"
      pattern: "parse_og_subgroups"
    - from: "src/jobforge/external/tbs/scraper.py"
      to: "src/jobforge/external/tbs/link_fetcher.py"
      via: "fetch_og_definition for embedded links"
      pattern: "fetch_og_definition"
---

<objective>
Extend the existing TBS scraper to capture occupational group subgroups and definitions from embedded links.

Purpose: The existing scraper captures the main OG table but not the detailed subgroup information or definition text from linked pages. This plan adds subgroup extraction and link following to provide complete OG data for downstream gold tables.

Output: Enhanced scraper with OGSubgroup models, subgroup parser, link fetcher for definitions, and scraped JSON files with full provenance.
</objective>

<execution_context>
@C:\Users\Administrator\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\Administrator\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/14-og-core/14-CONTEXT.md
@.planning/phases/14-og-core/14-RESEARCH.md

# Existing patterns to extend
@src/jobforge/external/tbs/scraper.py
@src/jobforge/external/tbs/models.py
@src/jobforge/external/tbs/parser.py
@src/jobforge/external/tbs/link_fetcher.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Extend TBS models for subgroups and definitions</name>
  <files>
    src/jobforge/external/tbs/models.py
  </files>
  <action>
Add Pydantic models for OG subgroups and definitions:

1. **OGSubgroup** model:
   - `og_code`: str (parent group code, e.g., "AS")
   - `subgroup_code`: str (e.g., "AS-01", "AS-02")
   - `subgroup_name`: str
   - `definition_url`: str | None (link to definition page)
   - `qualification_standard_url`: str | None (link to PDF)
   - `rates_of_pay_url`: str | None (link to pay rates)
   - `source_url`: str (TBS page URL)
   - `scraped_at`: datetime

2. **OGDefinition** model:
   - `og_code`: str
   - `subgroup_code`: str | None (None for parent OG definitions)
   - `definition_text`: str (extracted from linked page)
   - `page_title`: str
   - `source_url`: str (the linked page URL)
   - `scraped_at`: datetime

3. **OGScrapedData** container model:
   - `groups`: list[OGRow] (existing)
   - `subgroups`: list[OGSubgroup]
   - `definitions`: list[OGDefinition]
   - `scraped_at`: datetime
   - `source_url`: str

Follow existing ScrapedPage/OGRow patterns for consistency. Use `model_dump(mode="json")` for serialization.
  </action>
  <verify>
    `python -c "from jobforge.external.tbs.models import OGSubgroup, OGDefinition, OGScrapedData; print('Models imported successfully')"`
  </verify>
  <done>OGSubgroup, OGDefinition, and OGScrapedData models exist with all required fields and validation</done>
</task>

<task type="auto">
  <name>Task 2: Add subgroup parsing and definition link fetching</name>
  <files>
    src/jobforge/external/tbs/parser.py
    src/jobforge/external/tbs/link_fetcher.py
  </files>
  <action>
**In parser.py**, add `parse_og_subgroups()`:

1. Parse subgroup column from each table row (existing rows have subgroup data)
2. Extract subgroup codes (e.g., "AS-01", "AS-02") from the subgroup cells
3. Handle rows with multiple subgroups (some OGs have 5+ subgroups)
4. Extract embedded links for:
   - Definition pages
   - Qualification standard PDFs
   - Rates of pay pages
5. Return list of OGSubgroup objects with provenance

**In link_fetcher.py**, add `fetch_og_definition()`:

1. Accept a definition URL from the subgroup/group row
2. Make HTTP request with rate limiting (1-2 second delay per RESEARCH.md)
3. Parse the definition page using BeautifulSoup:
   - Find main content div (typically `class="mwsgeneric-base-html"` or similar)
   - Extract page title from h1
   - Extract definition text from content area
4. Return OGDefinition object with provenance
5. Handle 404s gracefully (log and continue, some links may be broken)

Use existing `extract_embedded_links()` pattern from parser.py. Add `time.sleep(1.5)` between requests to respect rate limits.
  </action>
  <verify>
    `python -c "from jobforge.external.tbs.parser import parse_og_subgroups; from jobforge.external.tbs.link_fetcher import fetch_og_definition; print('Functions imported')"`
  </verify>
  <done>parse_og_subgroups extracts subgroups from table rows; fetch_og_definition retrieves definition text from linked pages with rate limiting</done>
</task>

<task type="auto">
  <name>Task 3: Extend scraper and run full scrape</name>
  <files>
    src/jobforge/external/tbs/scraper.py
    data/tbs/og_subgroups_en.json
    data/tbs/og_definitions_en.json
    tests/external/tbs/test_og_scraper.py
  </files>
  <action>
**Extend TBSScraper class**:

1. Add `scrape_og_complete()` method that:
   - Calls existing `scrape_page()` for main table
   - Calls new `parse_og_subgroups()` on each row
   - Iterates unique definition URLs and calls `fetch_og_definition()` for each
   - Returns OGScrapedData with groups, subgroups, and definitions

2. Add `save_og_data()` method that saves:
   - `og_subgroups_en.json` - list of OGSubgroup objects
   - `og_definitions_en.json` - list of OGDefinition objects

3. Add `scrape_and_save_complete()` convenience method

**Run the scraper** (this is a one-time data collection):
```python
from jobforge.external.tbs.scraper import TBSScraper
scraper = TBSScraper()
scraper.scrape_and_save_complete()
```

**Add tests** in `tests/external/tbs/test_og_scraper.py`:
- Test OGSubgroup model validation
- Test OGDefinition model validation
- Test parse_og_subgroups with sample HTML
- Test fetch_og_definition with mocked response

Expected output:
- ~65 groups (already captured)
- ~200 subgroups with codes, names, and URLs
- ~50-100 definitions (not all have linked pages)
  </action>
  <verify>
    `pytest tests/external/tbs/test_og_scraper.py -v` passes
    `ls -la data/tbs/og_subgroups_en.json data/tbs/og_definitions_en.json` shows both files exist
    `python -c "import json; d=json.load(open('data/tbs/og_subgroups_en.json')); print(f'Subgroups: {len(d)}')"` shows ~200 subgroups
  </verify>
  <done>Complete OG data scraped: 65 groups, ~200 subgroups, definitions fetched; all files have provenance; tests pass</done>
</task>

</tasks>

<verification>
1. `pytest tests/external/tbs/ -v` - all TBS scraper tests pass
2. `python -c "import json; d=json.load(open('data/tbs/og_subgroups_en.json')); print(len(d))"` - returns ~200
3. `python -c "import json; d=json.load(open('data/tbs/og_definitions_en.json')); print(len(d))"` - returns 50+
4. JSON files contain `scraped_at` and `source_url` provenance fields
</verification>

<success_criteria>
- OGSubgroup and OGDefinition Pydantic models exist with validation
- parse_og_subgroups extracts subgroups from TBS table
- fetch_og_definition retrieves definition text with rate limiting
- og_subgroups_en.json contains ~200 subgroups with parent OG codes
- og_definitions_en.json contains fetched definition text
- All data has provenance (source_url, scraped_at)
- Tests pass for new scraper functionality
</success_criteria>

<output>
After completion, create `.planning/phases/14-og-core/14-01-SUMMARY.md`
</output>
