---
phase: 14-og-core
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - pyproject.toml
  - src/jobforge/external/tbs/pdf_extractor.py
  - data/tbs/og_qualifications/
  - data/tbs/og_qualification_text.json
  - tests/external/tbs/test_pdf_extractor.py
autonomous: true

must_haves:
  truths:
    - "PDF extractor downloads TBS qualification standard PDFs"
    - "PDF extractor extracts text with layout preservation"
    - "Extracted text is searchable for qualification criteria"
    - "All extracted data has provenance (source file, extracted_at)"
  artifacts:
    - path: "src/jobforge/external/tbs/pdf_extractor.py"
      provides: "PDF text extraction with pdfplumber"
      contains: "def extract_qualification_standard"
    - path: "data/tbs/og_qualifications/"
      provides: "Downloaded PDF files"
    - path: "data/tbs/og_qualification_text.json"
      provides: "Extracted text with provenance"
  key_links:
    - from: "src/jobforge/external/tbs/pdf_extractor.py"
      to: "pdfplumber"
      via: "pdfplumber.open() for PDF parsing"
      pattern: "pdfplumber\\.open"
---

<objective>
Add pdfplumber dependency and create PDF extraction module for TBS qualification standards.

Purpose: TBS publishes qualification standards as PDFs. This plan enables downloading and extracting text from these PDFs so qualification data can be loaded into searchable gold tables (enabling queries like "find OGs requiring Master's degree").

Output: PDF extractor module, downloaded qualification PDFs, extracted text JSON with full provenance.
</objective>

<execution_context>
@C:\Users\Administrator\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\Administrator\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/14-og-core/14-CONTEXT.md
@.planning/phases/14-og-core/14-RESEARCH.md

# Existing patterns
@src/jobforge/external/tbs/models.py
@src/jobforge/external/tbs/link_fetcher.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add pdfplumber dependency</name>
  <files>
    pyproject.toml
  </files>
  <action>
Add pdfplumber to project dependencies in pyproject.toml:

1. Add to `[project.dependencies]` section:
   ```
   "pdfplumber>=0.11.0,<0.12.0",
   ```

2. Run `pip install -e .` to install the new dependency

Per RESEARCH.md: pdfplumber 0.11.9 is the recommended choice for PDF text extraction with table detection and layout preservation. It's MIT-licensed (compatible with project) and handles TBS structured PDFs well.

Do NOT use pypdf (faster but worse table extraction) or PyMuPDF (GPL license conflict).
  </action>
  <verify>
    `python -c "import pdfplumber; print(f'pdfplumber {pdfplumber.__version__}')"`
  </verify>
  <done>pdfplumber >= 0.11.0 installed and importable</done>
</task>

<task type="auto">
  <name>Task 2: Create PDF extractor module with download and extraction</name>
  <files>
    src/jobforge/external/tbs/pdf_extractor.py
    data/tbs/og_qualifications/
  </files>
  <action>
Create `src/jobforge/external/tbs/pdf_extractor.py`:

1. **QualificationStandardText** Pydantic model:
   - `og_code`: str (extracted from filename, e.g., "AI")
   - `subgroup_code`: str | None (if subgroup-specific)
   - `full_text`: str (extracted text with layout)
   - `tables`: list[list[list[str]]] (extracted tables as nested lists)
   - `page_count`: int
   - `source_url`: str (original PDF URL)
   - `source_file`: str (local filename)
   - `extracted_at`: datetime
   - `pdf_metadata`: dict (from pdfplumber)

2. **download_qualification_pdf()** function:
   - Accept URL and output directory
   - Download PDF with httpx (use existing patterns)
   - Save to `data/tbs/og_qualifications/{og_code}_qual_standard.pdf`
   - Add 1.5 second delay between downloads (rate limiting)
   - Return Path to downloaded file

3. **extract_qualification_standard()** function:
   - Accept PDF path
   - Open with pdfplumber
   - Extract text with `layout=True` for spacing preservation
   - Extract tables from each page
   - Validate extraction (text length >= 100 chars, per RESEARCH.md)
   - Return QualificationStandardText object

4. **extract_all_qualification_standards()** function:
   - Accept list of PDF URLs (from scraped data)
   - Download each PDF (skip if already exists)
   - Extract text from each
   - Return list of QualificationStandardText objects

Create directory `data/tbs/og_qualifications/` for PDF storage.

Handle errors gracefully:
- Log and continue on download failures (some URLs may be broken)
- Log and continue on extraction failures (some PDFs may be malformed)
- Use `errors="replace"` for encoding issues
  </action>
  <verify>
    `python -c "from jobforge.external.tbs.pdf_extractor import extract_qualification_standard, download_qualification_pdf; print('Module imported')"`
    `ls -la data/tbs/og_qualifications/` shows directory exists
  </verify>
  <done>PDF extractor module with download and extraction functions; og_qualifications directory created</done>
</task>

<task type="auto">
  <name>Task 3: Run extraction and add tests</name>
  <files>
    data/tbs/og_qualification_text.json
    tests/external/tbs/test_pdf_extractor.py
  </files>
  <action>
**Run PDF extraction** (sample first, then full):

1. First, test with 3-5 sample PDFs to validate extraction works:
   ```python
   from jobforge.external.tbs.pdf_extractor import extract_all_qualification_standards
   import json

   # Get sample URLs from scraped data
   with open("data/tbs/og_subgroups_en.json") as f:
       subgroups = json.load(f)

   sample_urls = [s["qualification_standard_url"] for s in subgroups[:5] if s.get("qualification_standard_url")]
   results = extract_all_qualification_standards(sample_urls)
   print(f"Extracted {len(results)} PDFs")
   ```

2. If sample works, run full extraction and save to `og_qualification_text.json`:
   ```python
   all_urls = list(set(s["qualification_standard_url"] for s in subgroups if s.get("qualification_standard_url")))
   results = extract_all_qualification_standards(all_urls)

   with open("data/tbs/og_qualification_text.json", "w") as f:
       json.dump([r.model_dump(mode="json") for r in results], f, indent=2)
   ```

**Add tests** in `tests/external/tbs/test_pdf_extractor.py`:

1. Test QualificationStandardText model validation
2. Test extract_qualification_standard with a small test PDF (create fixture)
3. Test text length validation (raises on < 100 chars)
4. Test graceful handling of missing files

Note: Actual PDF download/extraction may take 10-20 minutes due to rate limiting. This is expected.
  </action>
  <verify>
    `pytest tests/external/tbs/test_pdf_extractor.py -v` passes
    `python -c "import json; d=json.load(open('data/tbs/og_qualification_text.json')); print(f'PDFs extracted: {len(d)}')"` shows extracted count
    `python -c "import json; d=json.load(open('data/tbs/og_qualification_text.json')); print(d[0].keys())"` shows provenance fields
  </verify>
  <done>Qualification PDFs downloaded; text extracted to og_qualification_text.json with provenance; tests pass</done>
</task>

</tasks>

<verification>
1. `python -c "import pdfplumber; print(pdfplumber.__version__)"` - version >= 0.11.0
2. `pytest tests/external/tbs/test_pdf_extractor.py -v` - all tests pass
3. `ls data/tbs/og_qualifications/*.pdf | wc -l` - shows downloaded PDF count
4. `python -c "import json; d=json.load(open('data/tbs/og_qualification_text.json')); print(len(d))"` - shows extraction count
</verification>

<success_criteria>
- pdfplumber >= 0.11.0 added to pyproject.toml and installed
- pdf_extractor.py module with download and extraction functions
- QualificationStandardText model with provenance fields
- og_qualifications/ directory with downloaded PDFs
- og_qualification_text.json with extracted text and provenance
- Tests pass for PDF extraction functionality
</success_criteria>

<output>
After completion, create `.planning/phases/14-og-core/14-02-SUMMARY.md`
</output>
