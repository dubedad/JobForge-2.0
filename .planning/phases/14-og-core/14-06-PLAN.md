---
phase: 14-og-core
plan: 06
type: tdd
wave: 3
depends_on: ["14-03"]
files_modified:
  - src/jobforge/concordance/noc_og.py
  - data/gold/bridge_noc_og.parquet
  - data/catalog/tables/bridge_noc_og.json
  - tests/concordance/test_noc_og.py
autonomous: true

must_haves:
  truths:
    - "User can look up which occupational group(s) a NOC code maps to"
    - "Mappings return ranked list (top 3-5) with confidence scores"
    - "Each mapping has source attribution (algorithmic vs published)"
    - "Each mapping has rationale text explaining why it maps"
    - "JD Builder Lite can consume bridge_noc_og for deterministic classification"
  artifacts:
    - path: "src/jobforge/concordance/noc_og.py"
      provides: "NOC-OG concordance matching with confidence scoring"
      exports: ["match_noc_to_og", "build_bridge_noc_og"]
    - path: "data/gold/bridge_noc_og.parquet"
      provides: "NOC-OG bridge table with ranked matches and provenance"
    - path: "data/catalog/tables/bridge_noc_og.json"
      provides: "Catalog metadata for bridge table"
  key_links:
    - from: "src/jobforge/concordance/noc_og.py"
      to: "data/gold/dim_noc.parquet"
      via: "loads NOC codes and titles for matching"
      pattern: "dim_noc\\.parquet"
    - from: "src/jobforge/concordance/noc_og.py"
      to: "data/gold/dim_og.parquet"
      via: "loads OG codes and names for matching"
      pattern: "dim_og\\.parquet"
    - from: "src/jobforge/concordance/noc_og.py"
      to: "rapidfuzz"
      via: "Jaro-Winkler similarity scoring"
      pattern: "fuzz\\.(ratio|WRatio|token_sort_ratio)"
---

<objective>
Build NOC-OG concordance bridge table using TDD approach.

Purpose: Per CONTEXT.md, enable JD Builder Lite to deterministically classify positions by occupational group. This is the core mapping that connects NOC codes to OG groups. Since no official TBS concordance exists (per RESEARCH.md), use algorithmic matching with full provenance.

Output: Concordance module with match_noc_to_og function, bridge_noc_og parquet table with ranked matches, catalog metadata. TDD approach ensures matching logic is correct.
</objective>

<execution_context>
@C:\Users\Administrator\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\Administrator\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/14-og-core/14-CONTEXT.md
@.planning/phases/14-og-core/14-RESEARCH.md

# Existing patterns for fuzzy matching
@src/jobforge/imputation/resolution.py

# Prior plan outputs (summaries will exist after execution)
# dim_og and dim_og_subgroup tables available from 14-03
</context>

<feature>
  <name>NOC-OG Concordance Matching</name>
  <files>
    src/jobforge/concordance/noc_og.py
    tests/concordance/test_noc_og.py
  </files>
  <behavior>
    Given a NOC code and title, return ranked list of OG matches with confidence scores.

    Test cases (input -> expected output patterns):

    1. "Financial managers" (NOC 10010) ->
       - Should match "FI - Financial Management" with high confidence (0.85+)
       - Source attribution: "algorithmic_rapidfuzz_high"
       - Rationale should explain the fuzzy match

    2. "Software engineers" (NOC 21231) ->
       - Should match "CS - Computer Systems" or "IT - Information Technology" with medium confidence
       - May return multiple matches (many-to-many is expected)

    3. "Administrative assistants" (NOC 13110) ->
       - Should match "AS - Administrative Services" with high confidence
       - Clear name alignment

    4. No reasonable match (obscure NOC title) ->
       - Should still return best guess with low confidence (< 0.70)
       - Per CONTEXT.md: "Always provide a suggestion, even for weak matches"

    5. Subgroup-level matching ->
       - If OG has subgroups, match to most specific subgroup when possible
       - E.g., "Senior financial analyst" -> "FI-03" not just "FI"

    Confidence tiers (from RESEARCH.md):
    - 1.00: Exact match (rare for algorithmic)
    - 0.85: High similarity (Jaro-Winkler >= 0.90)
    - 0.70: Medium similarity (Jaro-Winkler >= 0.80)
    - 0.50: Low similarity (Jaro-Winkler >= 0.70)
  </behavior>
  <implementation>
    1. Load dim_noc (516 unit groups with titles)
    2. Load dim_og (65 groups) and dim_og_subgroup (~200 subgroups)
    3. For each NOC, compute similarity against all OG names using rapidfuzz
    4. Use multiple strategies: fuzz.ratio, fuzz.token_sort_ratio, fuzz.WRatio
    5. Take best similarity score from strategies
    6. Map similarity to confidence tier
    7. Return top 5 matches sorted by confidence
    8. Store source_attribution and rationale for audit trail
  </implementation>
</feature>

<tasks>

<task type="auto">
  <name>Task 1: RED - Write failing tests for concordance matching</name>
  <files>
    tests/concordance/test_noc_og.py
  </files>
  <action>
Create `tests/concordance/test_noc_og.py` with failing tests:

```python
"""Tests for NOC-OG concordance matching."""
import pytest
from jobforge.concordance.noc_og import match_noc_to_og, NOCOGMatch


class TestMatchNocToOg:
    """Test match_noc_to_og function."""

    def test_financial_manager_matches_fi_group(self):
        """Financial managers should match FI group with high confidence."""
        matches = match_noc_to_og(noc_code="10010", noc_title="Financial managers")

        assert len(matches) >= 1
        assert any(m.og_code == "FI" for m in matches)

        fi_match = next(m for m in matches if m.og_code == "FI")
        assert fi_match.confidence >= 0.70  # At least medium confidence

    def test_returns_ranked_list(self):
        """Should return list sorted by confidence (highest first)."""
        matches = match_noc_to_og(noc_code="21231", noc_title="Software engineers")

        assert len(matches) >= 1
        assert len(matches) <= 5  # Top 5 max per CONTEXT.md

        # Verify sorted by confidence descending
        for i in range(len(matches) - 1):
            assert matches[i].confidence >= matches[i + 1].confidence

    def test_includes_source_attribution(self):
        """Each match should have source attribution."""
        matches = match_noc_to_og(noc_code="13110", noc_title="Administrative assistants")

        for match in matches:
            assert match.source_attribution is not None
            assert match.source_attribution.startswith("algorithmic_")

    def test_includes_rationale(self):
        """Each match should have human-readable rationale."""
        matches = match_noc_to_og(noc_code="10010", noc_title="Financial managers")

        for match in matches:
            assert match.rationale is not None
            assert len(match.rationale) > 10  # Non-trivial explanation

    def test_always_returns_suggestion(self):
        """Should always return at least one match, even low confidence."""
        # Obscure title unlikely to match well
        matches = match_noc_to_og(noc_code="99999", noc_title="Underwater basket weaver")

        assert len(matches) >= 1  # Always provide suggestion
        # May have low confidence, but should have a best guess

    def test_match_fields_complete(self):
        """NOCOGMatch should have all required fields."""
        matches = match_noc_to_og(noc_code="10010", noc_title="Financial managers")

        match = matches[0]
        assert hasattr(match, "noc_code")
        assert hasattr(match, "og_code")
        assert hasattr(match, "og_subgroup_code")  # Can be None
        assert hasattr(match, "confidence")
        assert hasattr(match, "similarity_score")
        assert hasattr(match, "source_attribution")
        assert hasattr(match, "rationale")
        assert hasattr(match, "matched_at")


class TestNOCOGMatchModel:
    """Test NOCOGMatch Pydantic model."""

    def test_confidence_in_valid_range(self):
        """Confidence should be 0.0 to 1.0."""
        matches = match_noc_to_og(noc_code="10010", noc_title="Financial managers")

        for match in matches:
            assert 0.0 <= match.confidence <= 1.0

    def test_similarity_score_in_valid_range(self):
        """Similarity score should be 0.0 to 1.0."""
        matches = match_noc_to_og(noc_code="10010", noc_title="Financial managers")

        for match in matches:
            assert 0.0 <= match.similarity_score <= 1.0
```

Run tests - they should FAIL (module doesn't exist yet):
```bash
pytest tests/concordance/test_noc_og.py -v
```
  </action>
  <verify>
    `pytest tests/concordance/test_noc_og.py -v 2>&1 | head -20` shows import errors or failures (tests fail because module doesn't exist)
  </verify>
  <done>Tests written and fail with ImportError (module doesn't exist)</done>
</task>

<task type="auto">
  <name>Task 2: GREEN - Implement concordance matching to pass tests</name>
  <files>
    src/jobforge/concordance/__init__.py
    src/jobforge/concordance/noc_og.py
  </files>
  <action>
Create `src/jobforge/concordance/__init__.py` (empty or with exports).

Create `src/jobforge/concordance/noc_og.py`:

```python
"""NOC-OG concordance matching with confidence scoring.

Maps NOC codes to TBS Occupational Groups using fuzzy matching
with full provenance tracking.
"""
from dataclasses import dataclass
from datetime import datetime, timezone
from functools import lru_cache
from pathlib import Path
from typing import Optional

import polars as pl
from pydantic import BaseModel
from rapidfuzz import fuzz

from jobforge.pipeline.config import PipelineConfig


# Confidence tiers (from RESEARCH.md)
CONFIDENCE_EXACT = 1.00
CONFIDENCE_HIGH = 0.85
CONFIDENCE_MEDIUM = 0.70
CONFIDENCE_LOW = 0.50


class NOCOGMatch(BaseModel):
    """A single NOC-to-OG match with confidence and provenance."""
    noc_code: str
    og_code: str
    og_subgroup_code: Optional[str] = None
    og_name: str
    confidence: float
    similarity_score: float
    source_attribution: str
    rationale: str
    matched_at: datetime


@lru_cache(maxsize=1)
def _load_og_groups(gold_path: Path) -> list[dict]:
    """Load OG groups from dim_og."""
    path = gold_path / "dim_og.parquet"
    if not path.exists():
        return []
    df = pl.read_parquet(path)
    return df.to_dicts()


@lru_cache(maxsize=1)
def _load_og_subgroups(gold_path: Path) -> list[dict]:
    """Load OG subgroups from dim_og_subgroup."""
    path = gold_path / "dim_og_subgroup.parquet"
    if not path.exists():
        return []
    df = pl.read_parquet(path)
    return df.to_dicts()


def match_noc_to_og(
    noc_code: str,
    noc_title: str,
    gold_path: Optional[Path] = None,
    top_n: int = 5,
    min_threshold: float = 0.50,
) -> list[NOCOGMatch]:
    """Match NOC occupation to OG groups using fuzzy matching.

    Args:
        noc_code: The NOC code (e.g., "10010", "21231")
        noc_title: The NOC occupation title
        gold_path: Path to gold layer (defaults to PipelineConfig)
        top_n: Maximum matches to return (default 5)
        min_threshold: Minimum similarity to include (default 0.50)

    Returns:
        List of NOCOGMatch sorted by confidence (highest first)
    """
    if gold_path is None:
        gold_path = PipelineConfig().gold_path()

    og_groups = _load_og_groups(gold_path)
    og_subgroups = _load_og_subgroups(gold_path)

    # Combine groups and subgroups for matching
    candidates = []
    for og in og_groups:
        candidates.append({
            "og_code": og["og_code"],
            "og_subgroup_code": None,
            "og_name": og["og_name"],
        })
    for sub in og_subgroups:
        candidates.append({
            "og_code": sub["og_code"],
            "og_subgroup_code": sub["og_subgroup_code"],
            "og_name": sub["og_subgroup_name"],
        })

    matches = []
    now = datetime.now(timezone.utc)

    for candidate in candidates:
        # Try multiple matching strategies
        ratio_score = fuzz.ratio(noc_title.lower(), candidate["og_name"].lower()) / 100.0
        token_score = fuzz.token_sort_ratio(noc_title.lower(), candidate["og_name"].lower()) / 100.0
        wratio_score = fuzz.WRatio(noc_title.lower(), candidate["og_name"].lower()) / 100.0

        best_score = max(ratio_score, token_score, wratio_score)

        if best_score < min_threshold:
            continue

        # Map to confidence tier
        if best_score >= 0.95:
            confidence = CONFIDENCE_EXACT
            tier = "exact"
        elif best_score >= 0.90:
            confidence = CONFIDENCE_HIGH
            tier = "high"
        elif best_score >= 0.80:
            confidence = CONFIDENCE_MEDIUM
            tier = "medium"
        else:
            confidence = CONFIDENCE_LOW
            tier = "low"

        matches.append(NOCOGMatch(
            noc_code=noc_code,
            og_code=candidate["og_code"],
            og_subgroup_code=candidate["og_subgroup_code"],
            og_name=candidate["og_name"],
            confidence=confidence,
            similarity_score=best_score,
            source_attribution=f"algorithmic_rapidfuzz_{tier}",
            rationale=f"Fuzzy match ({tier}): '{noc_title}' -> '{candidate['og_name']}' (score: {best_score:.2f})",
            matched_at=now,
        ))

    # Sort by confidence (descending), then similarity (descending)
    matches.sort(key=lambda m: (m.confidence, m.similarity_score), reverse=True)

    # Always return at least one match (best guess)
    if not matches and candidates:
        # Find best match even below threshold
        best_candidate = None
        best_score = 0.0
        for candidate in candidates:
            score = fuzz.WRatio(noc_title.lower(), candidate["og_name"].lower()) / 100.0
            if score > best_score:
                best_score = score
                best_candidate = candidate

        if best_candidate:
            matches.append(NOCOGMatch(
                noc_code=noc_code,
                og_code=best_candidate["og_code"],
                og_subgroup_code=best_candidate["og_subgroup_code"],
                og_name=best_candidate["og_name"],
                confidence=CONFIDENCE_LOW * (best_score / 0.50) if best_score < 0.50 else CONFIDENCE_LOW,
                similarity_score=best_score,
                source_attribution="algorithmic_rapidfuzz_best_guess",
                rationale=f"Best guess: '{noc_title}' -> '{best_candidate['og_name']}' (score: {best_score:.2f})",
                matched_at=now,
            ))

    return matches[:top_n]
```

Run tests - they should PASS:
```bash
pytest tests/concordance/test_noc_og.py -v
```
  </action>
  <verify>
    `pytest tests/concordance/test_noc_og.py -v` all tests pass
  </verify>
  <done>match_noc_to_og implemented and all tests pass</done>
</task>

<task type="auto">
  <name>Task 3: Build bridge table and create catalog metadata</name>
  <files>
    src/jobforge/concordance/noc_og.py
    data/gold/bridge_noc_og.parquet
    data/catalog/tables/bridge_noc_og.json
  </files>
  <action>
Add `build_bridge_noc_og()` function to `src/jobforge/concordance/noc_og.py`:

```python
def build_bridge_noc_og(
    gold_path: Optional[Path] = None,
    output_path: Optional[Path] = None,
) -> dict:
    """Build bridge_noc_og table by matching all NOC codes to OG groups.

    Creates a many-to-many bridge table with ranked matches and provenance.

    Args:
        gold_path: Path to gold layer (defaults to PipelineConfig)
        output_path: Output parquet path (defaults to gold_path/bridge_noc_og.parquet)

    Returns:
        Dict with output_path and row_count
    """
    if gold_path is None:
        gold_path = PipelineConfig().gold_path()
    if output_path is None:
        output_path = gold_path / "bridge_noc_og.parquet"

    # Load all NOC codes from dim_noc
    noc_path = gold_path / "dim_noc.parquet"
    noc_df = pl.read_parquet(noc_path)

    all_matches = []
    for row in noc_df.iter_rows(named=True):
        noc_code = row["unit_group_id"]  # or "noc_code" depending on schema
        noc_title = row["class_title"]

        matches = match_noc_to_og(noc_code, noc_title, gold_path)
        for match in matches:
            all_matches.append(match.model_dump())

    # Create DataFrame and save
    df = pl.DataFrame(all_matches)

    # Add provenance columns
    df = df.with_columns([
        pl.lit("dim_noc + dim_og").alias("_source_file"),
        pl.lit(datetime.now(timezone.utc).isoformat()).alias("_ingested_at"),
        pl.lit(f"noc_og_concordance_{datetime.now().strftime('%Y%m%d')}").alias("_batch_id"),
        pl.lit("gold").alias("_layer"),
    ])

    df.write_parquet(output_path)

    return {
        "output_path": str(output_path),
        "row_count": len(df),
        "noc_count": noc_df.shape[0],
        "match_count": len(all_matches),
    }
```

**Run the builder**:
```python
from jobforge.concordance.noc_og import build_bridge_noc_og
result = build_bridge_noc_og()
print(f"Created {result['row_count']} rows for {result['noc_count']} NOC codes")
```

**Create catalog metadata** `data/catalog/tables/bridge_noc_og.json`:
```json
{
  "table_name": "bridge_noc_og",
  "domain": "concordance",
  "description": "NOC to Occupational Group concordance - maps NOC codes to TBS OG groups with confidence scores",
  "source": "Algorithmically derived from dim_noc and dim_og using rapidfuzz fuzzy matching",
  "columns": {
    "noc_code": {"type": "VARCHAR", "description": "NOC unit group code", "foreign_key": "dim_noc.unit_group_id"},
    "og_code": {"type": "VARCHAR", "description": "Matched occupational group code", "foreign_key": "dim_og.og_code"},
    "og_subgroup_code": {"type": "VARCHAR", "description": "Matched subgroup code (if subgroup-level match)", "foreign_key": "dim_og_subgroup.og_subgroup_code"},
    "og_name": {"type": "VARCHAR", "description": "Name of matched OG/subgroup"},
    "confidence": {"type": "DOUBLE", "description": "Confidence score (1.0=exact, 0.85=high, 0.70=medium, 0.50=low)"},
    "similarity_score": {"type": "DOUBLE", "description": "Raw fuzzy similarity score (0.0-1.0)"},
    "source_attribution": {"type": "VARCHAR", "description": "How mapping was derived (algorithmic_rapidfuzz_*)"},
    "rationale": {"type": "VARCHAR", "description": "Human-readable explanation of mapping"},
    "matched_at": {"type": "TIMESTAMP", "description": "When mapping was computed"}
  },
  "relationships": [
    {"table": "dim_noc", "join": "bridge_noc_og.noc_code = dim_noc.unit_group_id", "type": "many-to-one"},
    {"table": "dim_og", "join": "bridge_noc_og.og_code = dim_og.og_code", "type": "many-to-one"},
    {"table": "dim_og_subgroup", "join": "bridge_noc_og.og_subgroup_code = dim_og_subgroup.og_subgroup_code", "type": "many-to-one"}
  ],
  "usage_hints": [
    "Use for JD Builder OG classification",
    "Filter by confidence >= 0.70 for reliable mappings",
    "Check source_attribution for audit trail",
    "Each NOC may have multiple OG matches (ranked by confidence)"
  ]
}
```
  </action>
  <verify>
    `pytest tests/concordance/test_noc_og.py -v` still passes
    `python -c "import polars as pl; df=pl.read_parquet('data/gold/bridge_noc_og.parquet'); print(f'Rows: {df.shape[0]}, Columns: {df.columns}')"` shows bridge table
    `ls -la data/catalog/tables/bridge_noc_og.json` shows catalog file exists
  </verify>
  <done>bridge_noc_og.parquet created with NOC-OG mappings; catalog metadata created; all tests pass</done>
</task>

</tasks>

<verification>
1. `pytest tests/concordance/test_noc_og.py -v` - all tests pass
2. `python -c "import polars as pl; print(pl.read_parquet('data/gold/bridge_noc_og.parquet').shape)"` - shows (N, columns)
3. Bridge table has confidence, source_attribution, rationale columns
4. Example query works:
   ```python
   import polars as pl
   df = pl.read_parquet("data/gold/bridge_noc_og.parquet")
   print(df.filter(pl.col("noc_code") == "10010").select(["og_code", "og_name", "confidence"]))
   ```
</verification>

<success_criteria>
- match_noc_to_og returns ranked list with confidence scores
- All matches have source_attribution and rationale
- Always returns at least one suggestion (even low confidence)
- bridge_noc_og.parquet created with all NOC-OG mappings
- FK relationships to dim_noc, dim_og, dim_og_subgroup
- Catalog metadata file created
- TDD cycle complete: RED->GREEN
</success_criteria>

<output>
After completion, create `.planning/phases/14-og-core/14-06-SUMMARY.md`
</output>
