---
phase: 14-og-core
plan: 03
type: execute
wave: 2
depends_on: ["14-01"]
files_modified:
  - src/jobforge/ingestion/og.py
  - data/gold/dim_og.parquet
  - data/gold/dim_og_subgroup.parquet
  - data/catalog/tables/dim_og.json
  - data/catalog/tables/dim_og_subgroup.json
  - tests/ingestion/test_og.py
autonomous: true

must_haves:
  truths:
    - "User can query all 65 TBS occupational groups with definitions"
    - "User can query ~200 subgroups linked to parent groups"
    - "All tables have full provenance (source URL, scrape timestamp)"
  artifacts:
    - path: "src/jobforge/ingestion/og.py"
      provides: "Medallion pipeline for dim_og and dim_og_subgroup"
      exports: ["ingest_dim_og", "ingest_dim_og_subgroup"]
    - path: "data/gold/dim_og.parquet"
      provides: "65 occupational groups dimension table"
    - path: "data/gold/dim_og_subgroup.parquet"
      provides: "~200 subgroups dimension table with parent FK"
    - path: "data/catalog/tables/dim_og.json"
      provides: "Catalog metadata for dim_og"
    - path: "data/catalog/tables/dim_og_subgroup.json"
      provides: "Catalog metadata for dim_og_subgroup"
  key_links:
    - from: "src/jobforge/ingestion/og.py"
      to: "src/jobforge/pipeline/engine.py"
      via: "PipelineEngine.run_full_pipeline"
      pattern: "engine\\.run_full_pipeline"
    - from: "data/gold/dim_og_subgroup.parquet"
      to: "data/gold/dim_og.parquet"
      via: "og_code foreign key relationship"
      pattern: "og_code"
---

<objective>
Create medallion ingestion pipelines for dim_og and dim_og_subgroup gold tables.

Purpose: Transform scraped OG JSON data into queryable gold tables following JobForge's bronze-silver-gold pipeline pattern. This enables users to query occupational groups and subgroups with full provenance.

Output: Two gold parquet tables (dim_og, dim_og_subgroup), catalog metadata files, ingestion module with pipeline functions.
</objective>

<execution_context>
@C:\Users\Administrator\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\Administrator\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/14-og-core/14-CONTEXT.md
@.planning/phases/14-og-core/14-RESEARCH.md

# Existing patterns to follow
@src/jobforge/ingestion/noc.py
@src/jobforge/pipeline/engine.py
@src/jobforge/pipeline/config.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create dim_og ingestion pipeline</name>
  <files>
    src/jobforge/ingestion/og.py
    data/gold/dim_og.parquet
  </files>
  <action>
Create `src/jobforge/ingestion/og.py` with `ingest_dim_og()` function:

1. **Bronze schema** (rename JSON fields to table columns):
   ```python
   bronze_schema = {
       "rename": {
           "group_abbrev": "og_code",          # e.g., "AS", "FI", "EC"
           "group_code": "og_numeric_code",     # e.g., "501", "502"
           "group_name": "og_name",             # e.g., "Administrative Services"
           "definition_url": "definition_url",
           "qualification_standard_url": "qualification_standard_url",
           "rates_of_pay_url": "rates_of_pay_url",
           "source_url": "_source_url",         # Provenance
           "scraped_at": "_scraped_at",         # Provenance
       },
       "cast": {
           "og_code": pl.Utf8,
           "og_numeric_code": pl.Utf8,
           "og_name": pl.Utf8,
       }
   }
   ```

2. **Silver transforms**:
   - `normalize_og_codes`: Uppercase og_code, strip whitespace
   - `dedupe_groups`: Remove duplicate og_codes (keep first occurrence)
   - `validate_required_fields`: Ensure og_code and og_name not null

3. **Gold transforms**:
   - `select_dim_og_columns`: Select final schema:
     - og_code (PK)
     - og_numeric_code
     - og_name
     - definition_url
     - qualification_standard_url
     - rates_of_pay_url
     - _source_url, _scraped_at, _source_file, _ingested_at, _batch_id, _layer

4. **Run pipeline**:
   ```python
   result = engine.run_full_pipeline(
       source_path=Path("data/tbs/occupational_groups_en.json"),
       table_name="dim_og",
       domain="occupational_groups",
       bronze_schema=bronze_schema,
       silver_transforms=[normalize_og_codes, dedupe_groups, validate_required_fields],
       gold_transforms=[select_dim_og_columns],
   )
   ```

Follow exactly the pattern from `ingestion/noc.py`. Use PipelineEngine for provenance tracking.
  </action>
  <verify>
    `python -c "from jobforge.ingestion.og import ingest_dim_og; print('Function imported')"`
    `python -c "from jobforge.ingestion.og import ingest_dim_og; r = ingest_dim_og(); print(f'Rows: {r[\"row_count\"]}')"` shows ~65 rows
  </verify>
  <done>ingest_dim_og creates dim_og.parquet with 65 occupational groups and full provenance</done>
</task>

<task type="auto">
  <name>Task 2: Create dim_og_subgroup ingestion pipeline</name>
  <files>
    src/jobforge/ingestion/og.py
    data/gold/dim_og_subgroup.parquet
  </files>
  <action>
Add `ingest_dim_og_subgroup()` function to `src/jobforge/ingestion/og.py`:

1. **Bronze schema**:
   ```python
   bronze_schema = {
       "rename": {
           "og_code": "og_code",                # FK to dim_og
           "subgroup_code": "og_subgroup_code", # e.g., "AS-01", "FI-02"
           "subgroup_name": "og_subgroup_name",
           "definition_url": "definition_url",
           "qualification_standard_url": "qualification_standard_url",
           "rates_of_pay_url": "rates_of_pay_url",
           "source_url": "_source_url",
           "scraped_at": "_scraped_at",
       },
       "cast": {
           "og_code": pl.Utf8,
           "og_subgroup_code": pl.Utf8,
           "og_subgroup_name": pl.Utf8,
       }
   }
   ```

2. **Silver transforms**:
   - `normalize_subgroup_codes`: Uppercase codes, strip whitespace
   - `dedupe_subgroups`: Remove duplicates on og_subgroup_code
   - `validate_parent_exists`: Ensure og_code exists in dim_og (FK validation)

3. **Gold transforms**:
   - `select_dim_og_subgroup_columns`: Final schema:
     - og_subgroup_code (PK)
     - og_code (FK to dim_og)
     - og_subgroup_name
     - definition_url
     - qualification_standard_url
     - rates_of_pay_url
     - _source_url, _scraped_at, _source_file, _ingested_at, _batch_id, _layer

4. **Source**: `data/tbs/og_subgroups_en.json` (from Plan 14-01)

Note: dim_og must be ingested first since dim_og_subgroup has FK dependency.
  </action>
  <verify>
    `python -c "from jobforge.ingestion.og import ingest_dim_og_subgroup; print('Function imported')"`
    `python -c "from jobforge.ingestion.og import ingest_dim_og_subgroup; r = ingest_dim_og_subgroup(); print(f'Rows: {r[\"row_count\"]}')"` shows ~200 rows
  </verify>
  <done>ingest_dim_og_subgroup creates dim_og_subgroup.parquet with ~200 subgroups linked to parent OGs</done>
</task>

<task type="auto">
  <name>Task 3: Create catalog metadata and tests</name>
  <files>
    data/catalog/tables/dim_og.json
    data/catalog/tables/dim_og_subgroup.json
    tests/ingestion/test_og.py
  </files>
  <action>
**Create catalog metadata** files:

1. `data/catalog/tables/dim_og.json`:
   ```json
   {
     "table_name": "dim_og",
     "domain": "occupational_groups",
     "description": "TBS Occupational Groups - 65 federal public service classification groups",
     "source": "Treasury Board Secretariat",
     "source_url": "https://www.canada.ca/en/treasury-board-secretariat/services/collective-agreements/occupational-groups.html",
     "columns": {
       "og_code": {"type": "VARCHAR", "description": "Occupational group code (e.g., AS, FI, EC)", "primary_key": true},
       "og_numeric_code": {"type": "VARCHAR", "description": "Numeric group code"},
       "og_name": {"type": "VARCHAR", "description": "Full name of occupational group"},
       "definition_url": {"type": "VARCHAR", "description": "URL to group definition page"},
       "qualification_standard_url": {"type": "VARCHAR", "description": "URL to qualification standard PDF"},
       "rates_of_pay_url": {"type": "VARCHAR", "description": "URL to rates of pay page"}
     },
     "relationships": [
       {"table": "dim_og_subgroup", "join": "dim_og.og_code = dim_og_subgroup.og_code", "type": "one-to-many"}
     ]
   }
   ```

2. `data/catalog/tables/dim_og_subgroup.json`:
   ```json
   {
     "table_name": "dim_og_subgroup",
     "domain": "occupational_groups",
     "description": "TBS Occupational Group Subgroups - ~200 classification subgroups linked to parent groups",
     "source": "Treasury Board Secretariat",
     "source_url": "https://www.canada.ca/en/treasury-board-secretariat/services/collective-agreements/occupational-groups.html",
     "columns": {
       "og_subgroup_code": {"type": "VARCHAR", "description": "Subgroup code (e.g., AS-01, FI-02)", "primary_key": true},
       "og_code": {"type": "VARCHAR", "description": "Parent occupational group code", "foreign_key": "dim_og.og_code"},
       "og_subgroup_name": {"type": "VARCHAR", "description": "Full name of subgroup"},
       "definition_url": {"type": "VARCHAR", "description": "URL to subgroup definition page"},
       "qualification_standard_url": {"type": "VARCHAR", "description": "URL to qualification standard PDF"},
       "rates_of_pay_url": {"type": "VARCHAR", "description": "URL to rates of pay page"}
     },
     "relationships": [
       {"table": "dim_og", "join": "dim_og_subgroup.og_code = dim_og.og_code", "type": "many-to-one"}
     ]
   }
   ```

**Add tests** in `tests/ingestion/test_og.py`:
- Test ingest_dim_og produces expected row count (~65)
- Test ingest_dim_og_subgroup produces expected row count (~200)
- Test og_code FK relationship (all subgroup og_codes exist in dim_og)
- Test provenance columns exist (_source_url, _scraped_at, _ingested_at)
- Test no null values in required fields (og_code, og_name)
  </action>
  <verify>
    `pytest tests/ingestion/test_og.py -v` passes
    `ls -la data/catalog/tables/dim_og*.json` shows both catalog files
    `python -c "import polars as pl; df=pl.read_parquet('data/gold/dim_og.parquet'); print(df.columns)"` shows provenance columns
  </verify>
  <done>Catalog metadata files created; tests pass for both dim_og and dim_og_subgroup pipelines; FK relationship validated</done>
</task>

</tasks>

<verification>
1. `pytest tests/ingestion/test_og.py -v` - all tests pass
2. `python -c "import polars as pl; print(pl.read_parquet('data/gold/dim_og.parquet').shape)"` - shows (65, N)
3. `python -c "import polars as pl; print(pl.read_parquet('data/gold/dim_og_subgroup.parquet').shape)"` - shows (~200, N)
4. Both parquet files have provenance columns (_source_url, _scraped_at, _ingested_at, _batch_id)
5. Catalog JSON files exist and are valid JSON
</verification>

<success_criteria>
- ingest_dim_og function creates dim_og.parquet with 65 OGs
- ingest_dim_og_subgroup function creates dim_og_subgroup.parquet with ~200 subgroups
- All subgroup og_codes exist in dim_og (FK integrity)
- Both tables have full provenance columns
- Catalog metadata files created for both tables
- Tests pass for ingestion and FK validation
</success_criteria>

<output>
After completion, create `.planning/phases/14-og-core/14-03-SUMMARY.md`
</output>
