---
phase: 10-governance-conversational
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/jobforge/governance/compliance/__init__.py
  - src/jobforge/governance/compliance/models.py
  - src/jobforge/governance/compliance/dadm.py
  - src/jobforge/governance/compliance/dama.py
  - src/jobforge/governance/compliance/classification.py
  - src/jobforge/cli/commands.py
  - tests/governance/test_compliance_models.py
  - tests/governance/test_dadm.py
  - tests/governance/test_dama.py
  - tests/governance/test_classification.py
autonomous: true

must_haves:
  truths:
    - "User can generate DADM compliance log showing mapping to Directive section 6.x requirements"
    - "User can generate DAMA compliance log showing mapping to 11 DMBOK knowledge areas"
    - "User can generate Classification compliance log showing NOC-based classification evidence"
    - "Each compliance log has timestamped entries with evidence references"
  artifacts:
    - path: "src/jobforge/governance/compliance/models.py"
      provides: "ComplianceStatus, TraceabilityEntry, ComplianceLog Pydantic models"
      exports: ["ComplianceStatus", "TraceabilityEntry", "ComplianceLog"]
    - path: "src/jobforge/governance/compliance/dadm.py"
      provides: "DADMComplianceLog with section 6.1-6.6 mappings"
      exports: ["DADMComplianceLog"]
    - path: "src/jobforge/governance/compliance/dama.py"
      provides: "DAMAComplianceLog with 11 knowledge area mappings"
      exports: ["DAMAComplianceLog"]
    - path: "src/jobforge/governance/compliance/classification.py"
      provides: "ClassificationComplianceLog with NOC alignment evidence"
      exports: ["ClassificationComplianceLog"]
  key_links:
    - from: "src/jobforge/governance/compliance/dadm.py"
      to: "data/catalog/lineage/*.json"
      via: "evidence_references pointing to lineage artifacts"
      pattern: "catalog/lineage"
    - from: "src/jobforge/governance/compliance/dama.py"
      to: "data/catalog/tables/*.json"
      via: "evidence_references pointing to table metadata"
      pattern: "catalog/tables"
    - from: "src/jobforge/cli/commands.py"
      to: "src/jobforge/governance/compliance/"
      via: "CLI commands importing compliance log generators"
      pattern: "from jobforge.governance.compliance"
---

<objective>
Create Requirements Traceability Matrix (RTM) based compliance logs for DADM, DAMA DMBOK, and Classification Policy frameworks.

Purpose: Enable users to demonstrate observable compliance with governance frameworks by showing chapter-and-verse mappings from WiQ artifacts to external requirements (GOV-02, GOV-03, GOV-04).

Output: Compliance log generators that produce JSON traceability matrices, plus CLI commands to generate and view compliance status.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/10-governance-conversational/10-RESEARCH.md

# Existing governance infrastructure
@src/jobforge/governance/models.py
@src/jobforge/governance/graph.py
@src/jobforge/governance/query.py
@src/jobforge/pipeline/config.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Compliance Models and DADM Log Generator</name>
  <files>
    - src/jobforge/governance/compliance/__init__.py
    - src/jobforge/governance/compliance/models.py
    - src/jobforge/governance/compliance/dadm.py
    - tests/governance/test_compliance_models.py
    - tests/governance/test_dadm.py
  </files>
  <action>
Create the compliance subpackage with RTM models and DADM compliance log generator.

**models.py:**
```python
from enum import Enum
from datetime import datetime
from pydantic import BaseModel, Field

class ComplianceStatus(str, Enum):
    COMPLIANT = "compliant"
    PARTIAL = "partial"
    NOT_APPLICABLE = "not_applicable"
    NOT_IMPLEMENTED = "not_implemented"

class TraceabilityEntry(BaseModel):
    requirement_id: str = Field(description="External requirement ID (e.g., DADM-6.2.3)")
    requirement_text: str = Field(description="Requirement description from source")
    section: str = Field(description="Chapter/section in source framework")
    status: ComplianceStatus
    evidence_type: str = Field(description="Type: artifact, process, documentation")
    evidence_references: list[str] = Field(description="Paths/IDs demonstrating compliance")
    notes: str = Field(default="")
    last_verified: datetime

class ComplianceLog(BaseModel):
    framework_name: str
    framework_version: str
    generated_at: datetime
    entries: list[TraceabilityEntry]

    @property
    def summary(self) -> dict[str, int]:
        counts = {s.value: 0 for s in ComplianceStatus}
        for entry in self.entries:
            counts[entry.status.value] += 1
        return counts
```

**dadm.py:**
Create DADMComplianceLog class that generates compliance entries for DADM Directive sections:
- 6.1 Algorithmic Impact Assessment (document that WiQ is decision-support, not decision-making)
- 6.2 Transparency (lineage query engine provides provenance explanation)
- 6.3 Data Quality (pipeline transforms with validation)
- 6.4 Legal Authority (reference NOC as authoritative source)
- 6.5 Procedural Fairness (not applicable - no individual decisions)
- 6.6 Recourse (not applicable - no individual decisions)

The generator should:
1. Accept PipelineConfig to access artifact paths
2. Scan actual artifacts (lineage logs, table metadata) for evidence
3. Return ComplianceLog with dated entries

**Tests:**
- Test ComplianceStatus enum values
- Test TraceabilityEntry validation
- Test ComplianceLog summary computation
- Test DADMComplianceLog generates valid entries
- Test DADM evidence references point to existing artifacts
  </action>
  <verify>
```bash
pytest tests/governance/test_compliance_models.py tests/governance/test_dadm.py -v
```
All tests pass, including evidence reference validation.
  </verify>
  <done>
DADM compliance log generates entries for sections 6.1-6.6 with evidence references pointing to actual WiQ artifacts. Tests validate model structure and evidence paths.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create DAMA and Classification Log Generators</name>
  <files>
    - src/jobforge/governance/compliance/dama.py
    - src/jobforge/governance/compliance/classification.py
    - tests/governance/test_dama.py
    - tests/governance/test_classification.py
  </files>
  <action>
Create DAMA DMBOK and Classification Policy compliance log generators.

**dama.py:**
Create DAMAComplianceLog class mapping to 11 DAMA DMBOK knowledge areas:

| Knowledge Area | WiQ Evidence | Status |
|----------------|--------------|--------|
| 1. Data Governance | src/jobforge/governance/ | COMPLIANT |
| 2. Data Architecture | data/catalog/schemas/wiq_schema.json | COMPLIANT |
| 3. Data Modeling and Design | data/catalog/schemas/ | COMPLIANT |
| 4. Data Storage and Operations | data/gold/*.parquet, src/jobforge/pipeline/ | COMPLIANT |
| 5. Data Security | (no PII in WiQ) | NOT_APPLICABLE |
| 6. Data Integration | src/jobforge/ingestion/, src/jobforge/external/ | COMPLIANT |
| 7. Metadata Management | data/catalog/tables/, data/catalog/lineage/ | COMPLIANT |
| 8. Data Quality | src/jobforge/pipeline/transforms.py | COMPLIANT |
| 9. Reference and Master Data | data/gold/dim_noc.parquet, data/gold/dim_occupations.parquet | COMPLIANT |
| 10. Data Warehousing and BI | data/gold/, src/jobforge/deployment/ | COMPLIANT |
| 11. Document and Content Management | (structured data focus) | NOT_APPLICABLE |

**classification.py:**
Create ClassificationComplianceLog class demonstrating NOC-based job classification compliance:
- NOC alignment: dim_noc table uses official NOC codes and hierarchy
- Hierarchy integrity: L5/L6/L7 hierarchy validated against NOC structure
- Title mapping: element_example_titles maps to NOC unit groups
- Attribute inheritance: imputation follows NOC hierarchy (L5 -> L6 -> L7)

The generator should scan gold tables and imputation module for evidence.

**Tests:**
- Test DAMA log generates entries for all 11 knowledge areas
- Test DAMA evidence references are valid paths
- Test Classification log validates NOC alignment
- Test Classification evidence includes gold tables and imputation code
  </action>
  <verify>
```bash
pytest tests/governance/test_dama.py tests/governance/test_classification.py -v
```
All tests pass, coverage includes all 11 DAMA areas and classification evidence.
  </verify>
  <done>
DAMA compliance log covers all 11 DMBOK knowledge areas with appropriate status. Classification log demonstrates NOC-based job classification compliance with hierarchy evidence.
  </done>
</task>

<task type="auto">
  <name>Task 3: Add CLI Commands for Compliance Logs</name>
  <files>
    - src/jobforge/cli/commands.py
    - src/jobforge/governance/compliance/__init__.py
  </files>
  <action>
Add CLI commands for generating and viewing compliance logs.

**Update __init__.py exports:**
```python
from jobforge.governance.compliance.models import (
    ComplianceStatus,
    TraceabilityEntry,
    ComplianceLog,
)
from jobforge.governance.compliance.dadm import DADMComplianceLog
from jobforge.governance.compliance.dama import DAMAComplianceLog
from jobforge.governance.compliance.classification import ClassificationComplianceLog

__all__ = [
    "ComplianceStatus",
    "TraceabilityEntry",
    "ComplianceLog",
    "DADMComplianceLog",
    "DAMAComplianceLog",
    "ClassificationComplianceLog",
]
```

**Add CLI commands to commands.py:**

```python
@app.command()
def compliance(
    framework: str = typer.Argument(..., help="Framework: dadm, dama, or classification"),
    output: Path = typer.Option(None, "--output", "-o", help="Output JSON file path"),
    summary_only: bool = typer.Option(False, "--summary", "-s", help="Show summary only"),
):
    """Generate or view compliance traceability log."""
    from jobforge.governance.compliance import (
        DADMComplianceLog,
        DAMAComplianceLog,
        ClassificationComplianceLog,
    )
    from jobforge.pipeline.config import PipelineConfig

    config = PipelineConfig()

    generators = {
        "dadm": DADMComplianceLog,
        "dama": DAMAComplianceLog,
        "classification": ClassificationComplianceLog,
    }

    if framework.lower() not in generators:
        console.print(f"[red]Unknown framework: {framework}[/red]")
        console.print(f"Available: {', '.join(generators.keys())}")
        raise typer.Exit(1)

    generator = generators[framework.lower()](config)
    log = generator.generate()

    if summary_only:
        # Show summary table
        ...
    elif output:
        output.write_text(log.model_dump_json(indent=2))
        console.print(f"[green]Compliance log written to {output}[/green]")
    else:
        # Pretty print with Rich
        ...
```

Implement Rich table formatting for summary view showing status counts and requirement coverage.
  </action>
  <verify>
```bash
# Test CLI commands
jobforge compliance dadm --summary
jobforge compliance dama --summary
jobforge compliance classification --summary

# Test JSON output
jobforge compliance dadm -o /tmp/dadm.json
cat /tmp/dadm.json | python -m json.tool | head -50
```
Commands execute without error, show correct summary counts, and produce valid JSON.
  </verify>
  <done>
CLI commands `jobforge compliance dadm|dama|classification` work with --summary and --output options. Users can generate compliance logs interactively or export to JSON.
  </done>
</task>

</tasks>

<verification>
**Phase-level verification:**

1. All three compliance log generators produce valid JSON:
```bash
jobforge compliance dadm -o data/catalog/compliance/dadm.json
jobforge compliance dama -o data/catalog/compliance/dama.json
jobforge compliance classification -o data/catalog/compliance/classification.json
```

2. Evidence references in logs point to actual artifacts:
```python
import json
from pathlib import Path

# Verify DADM evidence
dadm = json.loads(Path("data/catalog/compliance/dadm.json").read_text())
for entry in dadm["entries"]:
    for ref in entry["evidence_references"]:
        if not ref.startswith("src/") and not ref.startswith("data/"):
            continue
        assert Path(ref).exists() or "*" in ref, f"Missing: {ref}"
```

3. Full test suite passes:
```bash
pytest tests/governance/ -v
```
</verification>

<success_criteria>
- GOV-02: DADM compliance log has entries for sections 6.1-6.6 with evidence paths
- GOV-03: DAMA compliance log has entries for all 11 knowledge areas
- GOV-04: Classification compliance log shows NOC hierarchy alignment
- All logs have ComplianceStatus values (compliant, partial, not_applicable, not_implemented)
- CLI commands work: `jobforge compliance {dadm|dama|classification}`
- Tests verify model structure and evidence validity
</success_criteria>

<output>
After completion, create `.planning/phases/10-governance-conversational/10-01-SUMMARY.md`
</output>
