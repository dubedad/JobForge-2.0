---
phase: 02-data-ingestion
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/jobforge/sources/__init__.py
  - src/jobforge/sources/registry.py
  - src/jobforge/sources/models.py
  - src/jobforge/ingestion/__init__.py
  - src/jobforge/ingestion/noc.py
  - src/jobforge/ingestion/transforms.py
  - data/source/noc_structure_en.csv
  - tests/test_dim_noc_ingestion.py
autonomous: true

must_haves:
  truths:
    - "DIM NOC table exists in gold layer with 516 unit groups"
    - "NOC codes are 5-digit zero-padded format"
    - "Source registry can load and query source metadata"
    - "Provenance columns track source file through all layers"
  artifacts:
    - path: "src/jobforge/sources/registry.py"
      provides: "SourceRegistry class for managing source metadata"
      exports: ["SourceRegistry", "SourceMetadata"]
    - path: "src/jobforge/ingestion/noc.py"
      provides: "DIM NOC ingestion with transforms"
      exports: ["ingest_dim_noc"]
    - path: "data/gold/dim_noc.parquet"
      provides: "Gold layer DIM NOC table"
      contains: "516 rows with unit_group_id column"
  key_links:
    - from: "src/jobforge/ingestion/noc.py"
      to: "src/jobforge/pipeline/engine.py"
      via: "PipelineEngine.run_full_pipeline()"
      pattern: "engine\\.run_full_pipeline"
    - from: "src/jobforge/sources/registry.py"
      to: "src/jobforge/sources/models.py"
      via: "Pydantic model validation"
      pattern: "SourceMetadata\\("
---

<objective>
Create source registry infrastructure and ingest DIM NOC table to gold layer.

Purpose: DIM NOC is the spine of the butterfly semantic model. All other tables (attributes, COPS, Job Architecture) join to it via unit_group_id. This plan establishes the source metadata management pattern and delivers the foundational dimension table.

Output:
- SourceRegistry class with Pydantic models for source metadata
- DIM NOC ingested through full pipeline to gold layer
- Transform functions for NOC code normalization
- Tests verifying 516 unit groups in gold with correct schema
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-data-ingestion/02-RESEARCH.md

# Phase 1 implementation patterns
@src/jobforge/pipeline/engine.py
@src/jobforge/pipeline/layers.py
@src/jobforge/pipeline/models.py
@src/jobforge/pipeline/config.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Source Registry with Pydantic Models</name>
  <files>
    src/jobforge/sources/__init__.py
    src/jobforge/sources/registry.py
    src/jobforge/sources/models.py
  </files>
  <action>
Create a new `sources` module within jobforge for managing source metadata.

**src/jobforge/sources/models.py:**
```python
from pydantic import BaseModel, Field
from typing import Optional

class BilingualName(BaseModel):
    """Bilingual name for Canadian government sources."""
    en: str
    fr: str

class SchemaMetadata(BaseModel):
    """Schema classification metadata per prototype pattern."""
    source: str = Field(description="Source system: noc, oasis, cops, gc")
    data_type: str = Field(description="Data type: QL (qualitative), QN (quantitative)")
    subtype: Optional[str] = Field(default=None, description="Subtype: OA, NE, RF, 00")
    provides_categories: list[str] = Field(default_factory=list)

class BusinessMetadata(BaseModel):
    """Business context for a source."""
    business_purpose: str
    data_owner: str
    authority_level: str = Field(default="authoritative")

class SourceMetadata(BaseModel):
    """Complete metadata for a data source."""
    source_id: str = Field(description="Unique source identifier")
    name: BilingualName
    source_type: str = Field(description="Source type: open_data, local, api")
    url: Optional[str] = Field(default=None)
    schema_metadata: SchemaMetadata
    business_metadata: BusinessMetadata
    bronze_path: Optional[str] = Field(default=None)
```

**src/jobforge/sources/registry.py:**
```python
from pathlib import Path
from jobforge.sources.models import SourceMetadata
import json

class SourceRegistry:
    """Registry of data sources with metadata."""

    def __init__(self, sources: list[SourceMetadata]):
        self._sources = {s.source_id: s for s in sources}

    @classmethod
    def load(cls, path: Path) -> "SourceRegistry":
        """Load registry from sources.json file."""
        data = json.loads(path.read_text(encoding="utf-8"))
        sources = [SourceMetadata.model_validate(s) for s in data.get("sources", [])]
        return cls(sources)

    def get_source(self, source_id: str) -> SourceMetadata:
        """Get source metadata by ID."""
        if source_id not in self._sources:
            raise KeyError(f"Unknown source: {source_id}")
        return self._sources[source_id]

    def list_sources(self) -> list[str]:
        """List all source IDs."""
        return list(self._sources.keys())
```

**src/jobforge/sources/__init__.py:**
```python
from jobforge.sources.models import SourceMetadata, BilingualName, SchemaMetadata, BusinessMetadata
from jobforge.sources.registry import SourceRegistry

__all__ = ["SourceRegistry", "SourceMetadata", "BilingualName", "SchemaMetadata", "BusinessMetadata"]
```
  </action>
  <verify>
Run `python -c "from jobforge.sources import SourceRegistry, SourceMetadata; print('Import OK')"` - should print "Import OK" without errors.
  </verify>
  <done>
SourceRegistry class exists with load(), get_source(), list_sources() methods. Pydantic models validate source metadata structure.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create NOC Ingestion Module with Transforms</name>
  <files>
    src/jobforge/ingestion/__init__.py
    src/jobforge/ingestion/noc.py
    src/jobforge/ingestion/transforms.py
    data/source/noc_structure_en.csv
  </files>
  <action>
Create an `ingestion` module for source-specific ingestion logic.

**First, obtain the NOC structure CSV file:**
The NOC structure CSV should be placed in `data/source/`. The file can be downloaded from:
https://open.canada.ca/data/en/dataset/1feee3b5-8068-4dbb-b361-180875837593

For testing, create a minimal sample file at `data/source/noc_structure_en.csv` with this structure:
```csv
Level,Hierarchical structure,Code - NOC 2021 V1.0,Class title,Class definition
5,Unit group,00010,Legislators,Members of legislative bodies at the federal, provincial, territorial and municipal levels.
5,Unit group,00011,Senior Government Managers and Officials,Plan, organize, direct, control and evaluate major organizational units.
5,Unit group,00012,Senior Managers - Financial, Communications and Other Business Services,Plan, organize, direct, control and evaluate the operations of companies.
...
```

**src/jobforge/ingestion/transforms.py:**
```python
"""Transform functions for data ingestion.

Transforms are pure functions: LazyFrame -> LazyFrame.
They are passed to PipelineEngine.run_full_pipeline() for silver/gold layers.
"""
import polars as pl

def filter_unit_groups(df: pl.LazyFrame) -> pl.LazyFrame:
    """Filter to Level 5 (Unit Group) rows only.

    NOC structure contains all hierarchy levels (1-5).
    For DIM NOC, we only want the 516 unit groups at Level 5.
    """
    return df.filter(pl.col("level") == 5)

def derive_unit_group_id(df: pl.LazyFrame) -> pl.LazyFrame:
    """Create standardized unit_group_id from NOC code.

    NOC codes at Level 5 are 5-digit codes.
    Ensure zero-padding for consistency (e.g., '10' -> '00010').
    """
    return df.with_columns(
        pl.col("noc_code")
        .str.zfill(5)
        .alias("unit_group_id")
    )

def normalize_noc_code(df: pl.LazyFrame, code_column: str = "Code") -> pl.LazyFrame:
    """Normalize any NOC code column to 5-digit zero-padded format.

    Handles various input formats:
    - "10" -> "00010"
    - "00010" -> "00010" (no change)
    - "00010.00" -> "00010" (strip decimal portion)

    Args:
        df: Input LazyFrame
        code_column: Name of column containing NOC code

    Returns:
        LazyFrame with unit_group_id column added
    """
    return df.with_columns(
        pl.col(code_column)
        .str.replace(r"\\..*$", "")  # Remove decimal portion if present
        .str.zfill(5)
        .alias("unit_group_id")
    )

def derive_noc_element_code(df: pl.LazyFrame, code_column: str = "OaSIS Code - Final") -> pl.LazyFrame:
    """Extract 2-digit NOC Element Code from OaSIS profile code.

    OaSIS code format: XXXXX.YY (e.g., 00010.00)
    Element code: Last 2 characters after decimal
    """
    return df.with_columns(
        pl.col(code_column)
        .str.slice(-2)
        .alias("noc_element_code")
    )

def derive_unit_group_from_oasis(df: pl.LazyFrame, code_column: str = "OaSIS Code - Final") -> pl.LazyFrame:
    """Extract unit_group_id from OaSIS profile code.

    OaSIS code format: XXXXX.YY (e.g., 00010.00)
    Unit Group ID: First 5 characters, zero-padded
    """
    return df.with_columns(
        pl.col(code_column)
        .str.slice(0, 5)
        .str.zfill(5)
        .alias("unit_group_id")
    )
```

**src/jobforge/ingestion/noc.py:**
```python
"""DIM NOC table ingestion."""
from pathlib import Path
from typing import Optional

import polars as pl

from jobforge.pipeline.config import PipelineConfig
from jobforge.pipeline.engine import PipelineEngine
from jobforge.ingestion.transforms import filter_unit_groups, derive_unit_group_id


def ingest_dim_noc(
    source_path: Path,
    config: Optional[PipelineConfig] = None,
    table_name: str = "dim_noc",
) -> dict:
    """Ingest NOC structure CSV to gold layer as DIM NOC.

    Transforms applied:
    - Bronze: Rename columns to snake_case, cast Level to Int32
    - Silver: Filter to Level 5 (unit groups), derive unit_group_id
    - Gold: Final column selection

    Args:
        source_path: Path to NOC structure CSV file
        config: Pipeline configuration (defaults to PipelineConfig())
        table_name: Output table name (defaults to "dim_noc")

    Returns:
        Dict with gold_path, batch_id, and row counts
    """
    engine = PipelineEngine(config=config)

    # Bronze schema: rename columns to snake_case, cast types
    bronze_schema = {
        "rename": {
            "Level": "level",
            "Hierarchical structure": "hierarchical_structure",
            "Code - NOC 2021 V1.0": "noc_code",
            "Class title": "class_title",
            "Class definition": "class_definition",
        },
        "cast": {
            "level": pl.Int32,
        }
    }

    # Silver transforms: filter to unit groups, derive unit_group_id
    silver_transforms = [
        filter_unit_groups,
        derive_unit_group_id,
    ]

    # Gold transforms: select final columns
    def select_dim_noc_columns(df: pl.LazyFrame) -> pl.LazyFrame:
        """Select and order columns for DIM NOC gold table."""
        return df.select([
            "unit_group_id",
            "noc_code",
            "class_title",
            "class_definition",
            "hierarchical_structure",
            # Provenance columns are preserved automatically
            "_source_file",
            "_ingested_at",
            "_batch_id",
            "_layer",
        ])

    result = engine.run_full_pipeline(
        source_path=source_path,
        table_name=table_name,
        domain="noc",
        bronze_schema=bronze_schema,
        silver_transforms=silver_transforms,
        gold_transforms=[select_dim_noc_columns],
    )

    return result


if __name__ == "__main__":
    # Quick manual test
    import sys
    if len(sys.argv) > 1:
        source = Path(sys.argv[1])
    else:
        source = Path("data/source/noc_structure_en.csv")

    result = ingest_dim_noc(source)
    print(f"Ingested to: {result['gold_path']}")
    print(f"Rows: {pl.read_parquet(result['gold_path']).shape[0]}")
```

**src/jobforge/ingestion/__init__.py:**
```python
from jobforge.ingestion.noc import ingest_dim_noc
from jobforge.ingestion.transforms import (
    filter_unit_groups,
    derive_unit_group_id,
    normalize_noc_code,
    derive_noc_element_code,
    derive_unit_group_from_oasis,
)

__all__ = [
    "ingest_dim_noc",
    "filter_unit_groups",
    "derive_unit_group_id",
    "normalize_noc_code",
    "derive_noc_element_code",
    "derive_unit_group_from_oasis",
]
```

**data/source/noc_structure_en.csv:**
Create a sample file with at least 10 rows for testing. The full file will be obtained from Open Canada.
```csv
Level,Hierarchical structure,Code - NOC 2021 V1.0,Class title,Class definition
1,Broad occupational category,0,Legislative and senior management occupations,This broad occupational category comprises occupations concerned with formulating government policy and managing organizations.
5,Unit group,00010,Legislators,This unit group includes elected or appointed members of federal, provincial, territorial and municipal legislative bodies.
5,Unit group,00011,Senior government managers and officials,Senior government managers and officials plan, organize, direct, control and evaluate major organizational units.
5,Unit group,00012,Senior managers - financial and business services,Senior managers in this unit group plan, organize, direct, control and evaluate operations of companies.
5,Unit group,00013,Senior managers - trade, broadcasting and other services,Senior managers in this unit group plan, organize, direct, control and evaluate operations of trade organizations.
5,Unit group,00014,Senior managers - health, education, social and community services,Senior managers in this unit group plan, organize, direct, control and evaluate operations of health institutions.
5,Unit group,00015,Senior managers - construction, transportation and production utilities,Senior managers in this unit group plan, organize, direct, control and evaluate operations of construction companies.
5,Unit group,10010,Financial managers,Financial managers plan, organize, direct, control and evaluate the operation of financial departments.
5,Unit group,10011,Human resources managers,Human resources managers plan, organize, direct, control and evaluate the operations of human resources departments.
5,Unit group,10012,Purchasing managers,Purchasing managers plan, organize, direct, control and evaluate the activities of a purchasing department.
```
  </action>
  <verify>
Run these checks:
1. `python -c "from jobforge.ingestion import ingest_dim_noc; print('Import OK')"`
2. Ensure data/source/noc_structure_en.csv exists with sample data
3. Run `python -c "import polars as pl; df = pl.read_csv('data/source/noc_structure_en.csv'); print(f'Rows: {len(df)}, Columns: {df.columns}')"` - should show expected columns
  </verify>
  <done>
Ingestion module exists with ingest_dim_noc() function. Transform functions filter to unit groups and derive unit_group_id. Sample source CSV file exists for testing.
  </done>
</task>

<task type="auto">
  <name>Task 3: Create Tests and Run Full Ingestion</name>
  <files>
    tests/test_dim_noc_ingestion.py
    data/source/noc_structure_en.csv
  </files>
  <action>
Create comprehensive tests for DIM NOC ingestion and run the ingestion to verify gold table creation.

**tests/test_dim_noc_ingestion.py:**
```python
"""Tests for DIM NOC ingestion."""
from pathlib import Path

import polars as pl
import pytest

from jobforge.pipeline.config import PipelineConfig
from jobforge.ingestion import ingest_dim_noc
from jobforge.ingestion.transforms import (
    filter_unit_groups,
    derive_unit_group_id,
    normalize_noc_code,
)


@pytest.fixture
def test_config(tmp_path: Path) -> PipelineConfig:
    """Create a PipelineConfig using temporary directory."""
    return PipelineConfig(data_root=tmp_path / "data")


@pytest.fixture
def sample_noc_csv(tmp_path: Path) -> Path:
    """Create a sample NOC structure CSV for testing."""
    csv_path = tmp_path / "noc_structure.csv"
    csv_content = '''Level,Hierarchical structure,Code - NOC 2021 V1.0,Class title,Class definition
1,Broad occupational category,0,Legislative and senior management occupations,This broad category includes...
2,Major group,00,Senior management occupations,This major group includes...
5,Unit group,00010,Legislators,Legislators include elected officials...
5,Unit group,00011,Senior government managers,Senior government managers plan...
5,Unit group,00012,Senior managers - financial,Senior managers in financial...
5,Unit group,00013,Senior managers - trade,Senior managers in trade...
5,Unit group,10010,Financial managers,Financial managers plan...'''
    csv_path.write_text(csv_content, encoding="utf-8")
    return csv_path


class TestTransforms:
    """Tests for transform functions."""

    def test_filter_unit_groups(self) -> None:
        """Verify filter_unit_groups keeps only Level 5."""
        df = pl.LazyFrame({
            "level": [1, 2, 3, 4, 5, 5, 5],
            "noc_code": ["0", "00", "001", "0010", "00010", "00011", "10010"],
        })
        result = filter_unit_groups(df).collect()
        assert len(result) == 3
        assert all(result["level"] == 5)

    def test_derive_unit_group_id(self) -> None:
        """Verify derive_unit_group_id zero-pads codes."""
        df = pl.LazyFrame({
            "noc_code": ["10", "00010", "12345"],
        })
        result = derive_unit_group_id(df).collect()
        assert result["unit_group_id"].to_list() == ["00010", "00010", "12345"]

    def test_normalize_noc_code_strips_decimal(self) -> None:
        """Verify normalize_noc_code handles OaSIS-style codes."""
        df = pl.LazyFrame({
            "Code": ["00010.00", "12345.01", "10"],
        })
        result = normalize_noc_code(df).collect()
        assert result["unit_group_id"].to_list() == ["00010", "12345", "00010"]


class TestDimNocIngestion:
    """Tests for DIM NOC ingestion."""

    def test_ingest_dim_noc_creates_gold_file(
        self,
        sample_noc_csv: Path,
        test_config: PipelineConfig,
    ) -> None:
        """Verify ingest_dim_noc creates gold parquet file."""
        result = ingest_dim_noc(
            source_path=sample_noc_csv,
            config=test_config,
        )

        assert result["gold_path"].exists()
        assert result["gold_path"].suffix == ".parquet"

    def test_ingest_dim_noc_filters_to_unit_groups(
        self,
        sample_noc_csv: Path,
        test_config: PipelineConfig,
    ) -> None:
        """Verify only unit groups (Level 5) are in gold table."""
        result = ingest_dim_noc(
            source_path=sample_noc_csv,
            config=test_config,
        )

        gold_df = pl.read_parquet(result["gold_path"])

        # Sample has 5 unit groups (Level 5)
        assert len(gold_df) == 5

    def test_ingest_dim_noc_has_unit_group_id(
        self,
        sample_noc_csv: Path,
        test_config: PipelineConfig,
    ) -> None:
        """Verify gold table has unit_group_id column."""
        result = ingest_dim_noc(
            source_path=sample_noc_csv,
            config=test_config,
        )

        gold_df = pl.read_parquet(result["gold_path"])

        assert "unit_group_id" in gold_df.columns
        # All unit_group_ids should be 5 characters
        assert all(len(uid) == 5 for uid in gold_df["unit_group_id"])

    def test_ingest_dim_noc_has_provenance(
        self,
        sample_noc_csv: Path,
        test_config: PipelineConfig,
    ) -> None:
        """Verify gold table has provenance columns."""
        result = ingest_dim_noc(
            source_path=sample_noc_csv,
            config=test_config,
        )

        gold_df = pl.read_parquet(result["gold_path"])

        assert "_source_file" in gold_df.columns
        assert "_ingested_at" in gold_df.columns
        assert "_batch_id" in gold_df.columns
        assert "_layer" in gold_df.columns
        assert gold_df["_layer"][0] == "gold"

    def test_ingest_dim_noc_expected_columns(
        self,
        sample_noc_csv: Path,
        test_config: PipelineConfig,
    ) -> None:
        """Verify gold table has expected business columns."""
        result = ingest_dim_noc(
            source_path=sample_noc_csv,
            config=test_config,
        )

        gold_df = pl.read_parquet(result["gold_path"])

        expected_columns = [
            "unit_group_id",
            "noc_code",
            "class_title",
            "class_definition",
            "hierarchical_structure",
        ]
        for col in expected_columns:
            assert col in gold_df.columns, f"Missing column: {col}"
```

**Verification steps:**
1. Run the test suite: `pytest tests/test_dim_noc_ingestion.py -v`
2. If using real data, run: `python -m jobforge.ingestion.noc data/source/noc_structure_en.csv`
3. Verify gold file exists: `ls data/gold/dim_noc.parquet`
4. Query gold table: `python -c "import polars as pl; df = pl.read_parquet('data/gold/dim_noc.parquet'); print(f'Rows: {len(df)}'); print(df.head())"`

**Note on source file:**
For the actual production run with 516 unit groups, obtain the full NOC structure CSV from Open Canada:
https://open.canada.ca/data/en/dataset/1feee3b5-8068-4dbb-b361-180875837593

Download the English structure CSV and place it at `data/source/noc_structure_en.csv`. Then run the ingestion to verify all 516 unit groups appear in gold.
  </action>
  <verify>
Run: `pytest tests/test_dim_noc_ingestion.py -v`
All tests should pass. Expected output:
- test_filter_unit_groups PASSED
- test_derive_unit_group_id PASSED
- test_normalize_noc_code_strips_decimal PASSED
- test_ingest_dim_noc_creates_gold_file PASSED
- test_ingest_dim_noc_filters_to_unit_groups PASSED
- test_ingest_dim_noc_has_unit_group_id PASSED
- test_ingest_dim_noc_has_provenance PASSED
- test_ingest_dim_noc_expected_columns PASSED
  </verify>
  <done>
All tests pass. DIM NOC ingestion verified:
- Filters to Level 5 (unit groups) only
- Creates unit_group_id column with 5-digit zero-padded codes
- Preserves provenance columns through all layers
- Gold table has expected business columns
  </done>
</task>

</tasks>

<verification>
## Phase 2 Plan 01 Verification

### Automated Checks
1. **Import verification:** `python -c "from jobforge.sources import SourceRegistry; from jobforge.ingestion import ingest_dim_noc; print('OK')"`
2. **Test suite:** `pytest tests/test_dim_noc_ingestion.py -v` - all 8 tests pass
3. **Gold file exists:** `ls data/gold/dim_noc.parquet` returns file

### Manual Verification (with full NOC data)
1. Download full NOC structure from Open Canada
2. Run `python -m jobforge.ingestion.noc data/source/noc_structure_en.csv`
3. Query: `python -c "import polars as pl; df = pl.read_parquet('data/gold/dim_noc.parquet'); print(f'Rows: {len(df)}')"` should show 516 rows
4. Verify provenance: `python -c "import polars as pl; df = pl.read_parquet('data/gold/dim_noc.parquet'); print(df.select(['unit_group_id', '_source_file', '_layer']).head())"`
</verification>

<success_criteria>
1. SourceRegistry class loads source metadata from JSON
2. DIM NOC gold table exists with unit_group_id column
3. Only Level 5 rows (unit groups) are in gold table
4. All provenance columns preserved (_source_file, _ingested_at, _batch_id, _layer)
5. NOC codes are 5-digit zero-padded format
6. All tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/02-data-ingestion/02-01-SUMMARY.md`
</output>
