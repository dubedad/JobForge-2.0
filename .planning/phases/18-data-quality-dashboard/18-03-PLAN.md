---
phase: 18-data-quality-dashboard
plan: 03
type: execute
wave: 2
depends_on: ["18-01", "18-02"]
files_modified:
  - src/jobforge/quality/service.py
  - src/jobforge/quality/history.py
  - src/jobforge/quality/calculator.py
  - tests/quality/test_service.py
  - tests/quality/test_history.py
  - data/quality/snapshots/.gitkeep
autonomous: true

must_haves:
  truths:
    - "User can calculate quality scores for any gold table"
    - "Quality snapshots persist to parquet with date partitioning"
    - "User can load quality history for trend analysis"
    - "Degradation detection identifies quality decline"
  artifacts:
    - path: "src/jobforge/quality/service.py"
      provides: "QualityService orchestrating all metric calculations"
      exports: ["QualityService"]
    - path: "src/jobforge/quality/history.py"
      provides: "Snapshot storage and retrieval for historical trends"
      exports: ["save_quality_snapshot", "load_quality_history", "detect_degradation"]
    - path: "src/jobforge/quality/calculator.py"
      provides: "Dimension calculator aggregating all metrics"
      exports: ["DimensionCalculator", "calculate_all_dimensions"]
  key_links:
    - from: "src/jobforge/quality/service.py"
      to: "src/jobforge/quality/calculator.py"
      via: "Service delegates to calculator"
      pattern: "DimensionCalculator|calculate_all_dimensions"
    - from: "src/jobforge/quality/history.py"
      to: "data/quality/snapshots"
      via: "Parquet I/O with date partitioning"
      pattern: "write_parquet|read_parquet"
---

<objective>
Build the quality service layer that orchestrates metric calculation, aggregates scores using GC-aligned weights, and manages historical snapshots for trend tracking (DQ-01, DQ-06).

Purpose: Provides the unified interface that API, CLI, and dashboard will use. Handles the complexity of coordinating all dimension calculations and persisting results.

Output: QualityService class, history management, and degradation detection with 20+ tests.
</objective>

<execution_context>
@C:\Users\Administrator\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\Administrator\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

@.planning/phases/18-data-quality-dashboard/18-CONTEXT.md
@.planning/phases/18-data-quality-dashboard/18-RESEARCH.md

# Prior plan outputs
@.planning/phases/18-data-quality-dashboard/18-01-SUMMARY.md
@.planning/phases/18-data-quality-dashboard/18-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Quality Calculator and Service</name>
  <files>
    src/jobforge/quality/calculator.py
    src/jobforge/quality/service.py
    tests/quality/test_service.py
  </files>
  <action>
    Create DimensionCalculator in calculator.py:
    - calculate_all_dimensions(table_name) -> dict[DQDimension, float]
    - For automatable dimensions (Completeness, Accuracy, Coherence, Consistency, Timeliness): call metrics functions
    - For proxy dimensions (Relevance, Interpretability, Reliability, Access): implement proxy metrics:
      - Relevance: 100.0 if table has catalog entry, 50.0 otherwise
      - Interpretability: percentage of columns with descriptions in catalog
      - Reliability: 100.0 - (historical variance if available, else 85.0 default)
      - Access: 100.0 (all gold tables are queryable)
    - Handle errors gracefully (return 0.0 for failed calculations)

    Create QualityService in service.py:
    - __init__(config: PipelineConfig | None = None)
    - calculate_quality(table_name: str) -> QualityScore
    - calculate_all_tables() -> list[QualityScore]
    - refresh_snapshots() -> int (returns count of tables refreshed)
    - get_table_quality(table_name: str) -> QualityScore | None (from latest snapshot)
    - Caches results for session (invalidated on refresh)

    Tests:
    - QualityService.calculate_quality returns QualityScore with all dimensions
    - calculate_all_tables returns scores for all 39 gold tables
    - Proxy dimensions return reasonable scores
    - Service uses DimensionCalculator internally
  </action>
  <verify>pytest tests/quality/test_service.py -v</verify>
  <done>QualityService can calculate and return GC DQMF 9-dimension scores for any table</done>
</task>

<task type="auto">
  <name>Task 2: History Management and Degradation Detection</name>
  <files>
    src/jobforge/quality/history.py
    tests/quality/test_history.py
    data/quality/snapshots/.gitkeep
  </files>
  <action>
    Implement history.py:

    save_quality_snapshot(score: QualityScore, snapshot_dir: Path) -> Path:
    - Create date-partitioned path: snapshot_dir / YYYY-MM-DD / {table_name}.parquet
    - Save as parquet with columns: snapshot_date, table_name, dimension scores, overall_score, grade
    - Return path to saved file

    load_quality_history(table_name: str, snapshot_dir: Path, days: int = 90) -> pl.DataFrame:
    - Read all snapshots matching pattern: snapshot_dir / * / {table_name}.parquet
    - Filter to retention period (default 90 days)
    - Sort by snapshot_date ascending
    - Return DataFrame with columns: snapshot_date, overall_score, dimension scores

    detect_degradation(table_name: str, snapshot_dir: Path, threshold: float = 5.0) -> dict:
    - Load 90-day history
    - Threshold detection: Alert if latest score < 85%
    - Trend detection: Alert if 7-day MA declined > threshold% over 3 weeks
    - Return dict with: degraded (bool), reason (str), current_score, alert message

    cleanup_old_snapshots(snapshot_dir: Path, retention_days: int = 90) -> int:
    - Delete snapshots older than retention period
    - Return count of deleted files

    Retention strategy (from RESEARCH.md):
    - Daily snapshots for 30 days
    - Could extend to weekly aggregates later

    Create data/quality/snapshots/.gitkeep to ensure directory tracked.

    Tests:
    - save_quality_snapshot creates parquet in correct path
    - load_quality_history returns sorted DataFrame
    - detect_degradation returns degraded=True when score < 85
    - detect_degradation returns degraded=True on trend decline
    - cleanup_old_snapshots removes old files
  </action>
  <verify>pytest tests/quality/test_history.py -v</verify>
  <done>Quality snapshots persist to parquet with date partitioning, degradation detected via threshold and trend</done>
</task>

<task type="auto">
  <name>Task 3: Integration and Snapshot Directory</name>
  <files>
    src/jobforge/quality/__init__.py
    data/quality/snapshots/.gitkeep
  </files>
  <action>
    Update src/jobforge/quality/__init__.py to export public API:
    ```python
    from jobforge.quality.models import DQDimension, QualityScore, DimensionScore, QualityGrade
    from jobforge.quality.weights import GC_DIMENSION_WEIGHTS, calculate_weighted_score, get_grade
    from jobforge.quality.service import QualityService
    from jobforge.quality.history import save_quality_snapshot, load_quality_history, detect_degradation

    __all__ = [
        "DQDimension",
        "QualityScore",
        "DimensionScore",
        "QualityGrade",
        "GC_DIMENSION_WEIGHTS",
        "calculate_weighted_score",
        "get_grade",
        "QualityService",
        "save_quality_snapshot",
        "load_quality_history",
        "detect_degradation",
    ]
    ```

    Create data/quality/snapshots/.gitkeep (empty file to track directory).

    Create data/quality/config/ directory if not exists (from 18-01).

    Verify full integration:
    ```python
    from jobforge.quality import QualityService
    service = QualityService()
    score = service.calculate_quality("dim_noc")
    print(f"dim_noc: {score.overall_score:.1f}% ({score.grade})")
    ```
  </action>
  <verify>
    python -c "from jobforge.quality import QualityService; s = QualityService(); print(s.calculate_quality('dim_noc'))"
  </verify>
  <done>Quality module exports clean public API, snapshot directory exists</done>
</task>

</tasks>

<verification>
```bash
# Run all service and history tests
pytest tests/quality/test_service.py tests/quality/test_history.py -v

# Integration test: calculate quality for real table
python -c "
from jobforge.quality import QualityService
service = QualityService()
score = service.calculate_quality('dim_noc')
print(f'Table: {score.table_name}')
print(f'Overall: {score.overall_score:.1f}%')
print(f'Grade: {score.grade}')
for dim, s in score.dimension_scores.items():
    print(f'  {dim.value}: {s:.1f}%')
"

# Verify snapshot directory exists
ls data/quality/snapshots/
```
</verification>

<success_criteria>
- [ ] QualityService.calculate_quality returns complete QualityScore
- [ ] All 9 dimensions calculated (5 automatable + 4 proxy)
- [ ] save_quality_snapshot creates date-partitioned parquet
- [ ] load_quality_history returns filtered DataFrame
- [ ] detect_degradation identifies threshold and trend issues
- [ ] Quality module exports clean public API
- [ ] 20+ tests passing for service and history
</success_criteria>

<output>
After completion, create `.planning/phases/18-data-quality-dashboard/18-03-SUMMARY.md`
</output>
