---
phase: 18-data-quality-dashboard
plan: 04
type: execute
wave: 2
depends_on: ["18-01", "18-02"]
files_modified:
  - src/jobforge/api/quality.py
  - src/jobforge/api/routes.py
  - src/jobforge/cli/commands.py
  - tests/api/test_quality_routes.py
  - tests/cli/test_quality_commands.py
autonomous: true

must_haves:
  truths:
    - "User can query quality scores via GET /api/quality/table/{table}"
    - "User can list all tables with quality via GET /api/quality/tables"
    - "User can run quality check via CLI: jobforge quality check {table}"
    - "CLI outputs support --json and --csv formats"
  artifacts:
    - path: "src/jobforge/api/quality.py"
      provides: "FastAPI router for quality endpoints"
      exports: ["quality_router"]
    - path: "src/jobforge/cli/commands.py"
      provides: "Quality CLI subcommand group"
      contains: "quality_app"
  key_links:
    - from: "src/jobforge/api/quality.py"
      to: "src/jobforge/quality/service.py"
      via: "Router calls QualityService"
      pattern: "QualityService"
    - from: "src/jobforge/api/routes.py"
      to: "src/jobforge/api/quality.py"
      via: "Main app includes quality router"
      pattern: "include_router.*quality"
---

<objective>
Add data quality API endpoints (DQ-04) and CLI commands for quality checking with multiple output formats.

Purpose: Exposes quality scores via REST API for programmatic access (Orbit integration, scripts) and CLI for operator use. Follows existing JobForge patterns.

Output: Quality API router, CLI subcommand, and 15+ tests.
</objective>

<execution_context>
@C:\Users\Administrator\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\Administrator\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

@.planning/phases/18-data-quality-dashboard/18-CONTEXT.md
@.planning/phases/18-data-quality-dashboard/18-RESEARCH.md

# Existing API and CLI patterns
@src/jobforge/api/routes.py
@src/jobforge/cli/commands.py
@src/jobforge/api/errors.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Quality API Endpoints</name>
  <files>
    src/jobforge/api/quality.py
    src/jobforge/api/routes.py
    tests/api/test_quality_routes.py
  </files>
  <action>
    Create src/jobforge/api/quality.py:

    ```python
    from fastapi import APIRouter, HTTPException
    from pydantic import BaseModel
    from jobforge.quality import QualityService, QualityScore, DQDimension
    from jobforge.api.errors import TableNotFoundError

    quality_router = APIRouter(prefix="/api/quality", tags=["quality"])
    ```

    Endpoints:

    GET /api/quality/table/{table_name}
    - Returns QualityScore for single table
    - Response model: QualityScoreResponse (table_name, overall_score, grade, dimension_scores, snapshot_date)
    - Raises TableNotFoundError if table not in gold layer

    GET /api/quality/tables
    - Returns quality summary for all tables
    - Response model: QualityTableListResponse (tables: list, count: int)
    - Each table entry: table_name, overall_score, grade

    GET /api/quality/table/{table_name}/history
    - Returns historical scores for trend analysis
    - Query params: days (default 90)
    - Response model: QualityHistoryResponse (table_name, history: list[{date, score}])

    POST /api/quality/refresh
    - Triggers snapshot refresh for all tables
    - Returns count of tables refreshed
    - Response model: RefreshResponse (refreshed_count: int, timestamp: str)

    Update src/jobforge/api/routes.py:
    - Import quality_router from quality.py
    - Add api_app.include_router(quality_router) in create_api_app()

    Create response models as Pydantic classes:
    - QualityScoreResponse
    - QualityTableListResponse
    - QualityHistoryResponse
    - RefreshResponse

    Tests:
    - GET /api/quality/table/dim_noc returns 200 with score
    - GET /api/quality/table/nonexistent returns 404 RFC 9457
    - GET /api/quality/tables returns list of all tables
    - GET /api/quality/table/dim_noc/history returns historical data
    - POST /api/quality/refresh returns refresh count
  </action>
  <verify>pytest tests/api/test_quality_routes.py -v</verify>
  <done>Quality API endpoints return GC DQMF scores following JobForge patterns</done>
</task>

<task type="auto">
  <name>Task 2: Quality CLI Subcommand</name>
  <files>
    src/jobforge/cli/commands.py
    tests/cli/test_quality_commands.py
  </files>
  <action>
    Add quality subcommand group to commands.py (following caf_app pattern):

    ```python
    quality_app = typer.Typer(
        name="quality",
        help="Data quality monitoring commands",
    )
    ```

    Commands:

    jobforge quality check {table}
    - Calculate and display quality score for single table
    - Options: --json, --csv, --verbose
    - Default output: Rich table with dimension scores
    - JSON output: Full QualityScore as JSON
    - CSV output: dimension,score rows

    jobforge quality summary
    - Show quality summary for all tables
    - Options: --json, --csv, --sort (overall, name)
    - Default output: Rich table with traffic-light indicators
    - Show grade as color (green=A, yellow=B, red=C/D/F)

    jobforge quality refresh
    - Refresh quality snapshots for all tables
    - Options: --table (single table refresh)
    - Output: Progress bar, then summary table

    jobforge quality trends {table}
    - Show quality trend for table
    - Options: --days (default 30)
    - Default output: Sparkline-style ASCII trend + stats

    Register with main app:
    ```python
    app.add_typer(quality_app, name="quality")
    ```

    Output format decisions (from CONTEXT.md):
    - Table: Rich table with colors
    - JSON: Full model dump
    - CSV: Standard comma-separated

    Tests (use CliRunner from typer.testing):
    - quality check dim_noc outputs Rich table
    - quality check dim_noc --json outputs valid JSON
    - quality check dim_noc --csv outputs CSV format
    - quality summary shows all tables
    - quality refresh runs without error
  </action>
  <verify>
    # Run CLI tests
    pytest tests/cli/test_quality_commands.py -v

    # Manual verification
    jobforge quality check dim_noc
    jobforge quality summary
  </verify>
  <done>CLI commands support check, summary, refresh, trends with --json/--csv output</done>
</task>

</tasks>

<verification>
```bash
# Run all API and CLI tests
pytest tests/api/test_quality_routes.py tests/cli/test_quality_commands.py -v

# Test API endpoints
curl http://localhost:8000/api/quality/table/dim_noc
curl http://localhost:8000/api/quality/tables

# Test CLI commands
jobforge quality check dim_noc
jobforge quality check dim_noc --json
jobforge quality summary
```
</verification>

<success_criteria>
- [ ] GET /api/quality/table/{table} returns QualityScore
- [ ] GET /api/quality/tables returns all table summaries
- [ ] GET /api/quality/table/{table}/history returns historical data
- [ ] POST /api/quality/refresh triggers snapshot update
- [ ] jobforge quality check {table} shows Rich table
- [ ] --json and --csv output formats work
- [ ] jobforge quality summary shows traffic-light grid
- [ ] 15+ tests passing for API and CLI
</success_criteria>

<output>
After completion, create `.planning/phases/18-data-quality-dashboard/18-04-SUMMARY.md`
</output>
