---
phase: 15-caf-core
plan: 02
type: execute
wave: 2
depends_on: ["15-01"]
files_modified:
  - src/jobforge/external/caf/link_fetcher.py
  - src/jobforge/external/caf/models.py
  - data/caf/occupations.json
  - data/caf/job_families.json
  - tests/external/test_caf_link_fetcher.py
autonomous: true

must_haves:
  truths:
    - "User can access full career details for all 107 CAF occupations"
    - "Bilingual content stored in same record (EN/FR columns, not rows)"
    - "Related civilian occupations extracted from career pages"
    - "Job families inferred from career groupings"
  artifacts:
    - path: "src/jobforge/external/caf/link_fetcher.py"
      provides: "Career detail fetcher following TBS link_fetcher pattern"
      exports: ["fetch_career_detail", "CAFLinkFetcher"]
    - path: "data/caf/occupations.json"
      provides: "107 complete CAF occupations with bilingual content"
    - path: "data/caf/job_families.json"
      provides: "12 CAF job families inferred from career data"
  key_links:
    - from: "src/jobforge/external/caf/link_fetcher.py"
      to: "data/caf/careers_en.json"
      via: "Reads career URLs from listing scrape"
      pattern: "careers_en\\.json"
    - from: "src/jobforge/external/caf/link_fetcher.py"
      to: "src/jobforge/external/caf/models.py"
      via: "CAFOccupation model instantiation"
      pattern: "CAFOccupation"
---

<objective>
Fetch full career details from individual career pages and extract job families.

Purpose: With career URLs from Plan 01, fetch each career page to extract full details (overview, training, requirements, related civilian occupations). Infer job families from career groupings per RESEARCH.md recommendation.

Output: occupations.json with 107 complete CAF occupations (bilingual), job_families.json with 12 inferred families.
</objective>

<execution_context>
@C:\Users\Administrator\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\Administrator\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/15-caf-core/15-CONTEXT.md
@.planning/phases/15-caf-core/15-RESEARCH.md

# Prior plan output
@.planning/phases/15-caf-core/15-01-SUMMARY.md

# Existing patterns
@src/jobforge/external/tbs/link_fetcher.py
@src/jobforge/external/caf/models.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create career detail fetcher</name>
  <files>
    src/jobforge/external/caf/link_fetcher.py
  </files>
  <action>
Create `src/jobforge/external/caf/link_fetcher.py` following TBS link_fetcher pattern:

```python
"""Career detail fetcher for forces.ca individual career pages.

Per CONTEXT.md: Capture ALL fields, scrape both EN and FR, store bilingual in same row.
Per RESEARCH.md: Rate limit 1.5s between requests, retry with exponential backoff.
"""
import json
import time
from datetime import datetime, timezone
from pathlib import Path
from typing import Any

import httpx
import structlog
from bs4 import BeautifulSoup
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type

from .models import CAFCareerListing, CAFOccupation, CAFProvenance
from .parser import compute_content_hash

logger = structlog.get_logger(__name__)

REQUEST_DELAY_SECONDS = 1.5

# URL patterns for career pages
CAREER_URL_PATTERNS = {
    "en": "https://forces.ca/en/career/{slug}/",
    "fr": "https://forces.ca/fr/carriere/{slug}/",
}


class CAFLinkFetcher:
    """Fetches full career details from individual career pages.

    Follows TBS LinkMetadataFetcher pattern with bilingual support.
    Per CONTEXT.md decision: Store EN/FR in separate columns, not separate rows.
    """

    def __init__(self, output_dir: str | Path = "data/caf"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.client = httpx.Client(
            timeout=30.0,
            follow_redirects=True,
            limits=httpx.Limits(max_connections=5),
        )

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1.5, min=2, max=10),
        retry=retry_if_exception_type((httpx.HTTPStatusError, httpx.TimeoutException)),
    )
    def _fetch(self, url: str) -> str:
        """Fetch URL with retry."""
        response = self.client.get(url)
        response.raise_for_status()
        return response.text

    def _parse_career_page(self, html: str, language: str) -> dict[str, Any]:
        """Extract all fields from career page.

        Per CONTEXT.md: Capture ALL available fields.
        """
        soup = BeautifulSoup(html, 'lxml')
        content_hash = compute_content_hash(html)

        # Extract title
        title_tag = soup.find('h1')
        title = title_tag.get_text(strip=True) if title_tag else ""

        # Extract sections - forces.ca uses section IDs or headings
        def extract_section(section_ids: list[str], headings: list[str]) -> str | None:
            """Extract text from section by ID or heading."""
            for sid in section_ids:
                section = soup.find(id=sid)
                if section:
                    return section.get_text(separator="\n", strip=True)

            for heading in headings:
                h_tag = soup.find(['h2', 'h3'], string=lambda s: s and heading.lower() in s.lower())
                if h_tag:
                    content = []
                    for sibling in h_tag.find_next_siblings():
                        if sibling.name in ['h2', 'h3']:
                            break
                        content.append(sibling.get_text(strip=True))
                    return "\n\n".join(filter(None, content))
            return None

        overview = extract_section(['overview', 'apercu'], ['Overview', 'Apercu', 'About'])
        responsibilities = extract_section(['responsibilities', 'responsabilites'], ['Responsibilities', 'Responsabilites', 'Duties'])
        training = extract_section(['training', 'formation'], ['Training', 'Formation', 'Education'])
        entry_plans = extract_section(['entry-plans', 'plans-enrolement'], ['Entry Plans', 'Plans', 'How to Join'])
        requirements = extract_section(['requirements', 'exigences'], ['Requirements', 'Exigences', 'Qualifications'])

        # Extract related civilian occupations
        civilian_occs = []
        civilian_section = soup.find(id='related-civilian-occupations') or soup.find(
            ['h2', 'h3'], string=lambda s: s and 'civilian' in s.lower()
        )
        if civilian_section:
            # Look for list items or following paragraphs
            for li in soup.find_all('li'):
                text = li.get_text(strip=True)
                if len(text) < 100:  # Likely an occupation title, not prose
                    civilian_occs.append(text)

        # Extract related careers
        related_careers = []
        for link in soup.find_all('a', href=True):
            href = link['href']
            pattern = f"/{language}/career/" if language == "en" else f"/{language}/carriere/"
            if pattern in href and href != soup.find('link', rel='canonical')['href'] if soup.find('link', rel='canonical') else True:
                slug = href.rstrip('/').split('/')[-1]
                if slug and slug not in related_careers:
                    related_careers.append(slug)

        # Extract military branch if visible
        military_branch = None
        for text in soup.stripped_strings:
            text_lower = text.lower()
            if 'army' in text_lower or 'armee' in text_lower:
                military_branch = 'Army'
                break
            elif 'navy' in text_lower or 'marine' in text_lower:
                military_branch = 'Navy'
                break
            elif 'air force' in text_lower or 'force aerienne' in text_lower:
                military_branch = 'Air Force'
                break

        return {
            'title': title,
            'overview': overview,
            'responsibilities': responsibilities,
            'training': training,
            'entry_plans': entry_plans,
            'requirements': requirements,
            'related_civilian_occupations': civilian_occs[:10],  # Cap at 10
            'related_careers': related_careers[:10],  # Cap at 10
            'military_branch': military_branch,
            'content_hash': content_hash,
        }

    def fetch_career_detail(self, career_slug: str) -> CAFOccupation | None:
        """Fetch career details for both languages and merge into single record.

        Per CONTEXT.md: Bilingual in same record using separate columns.
        """
        scraped_at = datetime.now(timezone.utc)

        # Build URLs
        url_en = CAREER_URL_PATTERNS["en"].format(slug=career_slug)
        url_fr = CAREER_URL_PATTERNS["fr"].format(slug=career_slug)

        try:
            # Fetch EN
            logger.debug("fetching_career_en", slug=career_slug, url=url_en)
            html_en = self._fetch(url_en)
            data_en = self._parse_career_page(html_en, "en")
            time.sleep(REQUEST_DELAY_SECONDS)

            # Fetch FR
            logger.debug("fetching_career_fr", slug=career_slug, url=url_fr)
            html_fr = self._fetch(url_fr)
            data_fr = self._parse_career_page(html_fr, "fr")
            time.sleep(REQUEST_DELAY_SECONDS)

            # Merge into single CAFOccupation
            return CAFOccupation(
                occupation_id=career_slug,
                title_en=data_en['title'],
                title_fr=data_fr['title'],
                overview_en=data_en['overview'],
                overview_fr=data_fr['overview'],
                responsibilities_en=data_en['responsibilities'],
                responsibilities_fr=data_fr['responsibilities'],
                training_en=data_en['training'],
                training_fr=data_fr['training'],
                entry_plans_en=data_en['entry_plans'],
                entry_plans_fr=data_fr['entry_plans'],
                requirements_en=data_en['requirements'],
                requirements_fr=data_fr['requirements'],
                related_civilian_occupations=data_en['related_civilian_occupations'],
                related_careers=data_en['related_careers'],
                military_branch=data_en['military_branch'],
                source_url_en=url_en,
                source_url_fr=url_fr,
                scraped_at=scraped_at,
                content_hash_en=data_en['content_hash'],
                content_hash_fr=data_fr['content_hash'],
            )

        except httpx.HTTPStatusError as e:
            logger.warning("career_fetch_failed", slug=career_slug, status=e.response.status_code)
            time.sleep(REQUEST_DELAY_SECONDS)
            return None
        except Exception as e:
            logger.warning("career_fetch_error", slug=career_slug, error=str(e))
            time.sleep(REQUEST_DELAY_SECONDS)
            return None

    def fetch_all_careers(self, careers_json_path: Path | None = None) -> list[CAFOccupation]:
        """Fetch details for all careers from listing JSON.

        Args:
            careers_json_path: Path to careers_en.json from Plan 01.
                             Defaults to data/caf/careers_en.json.

        Returns:
            List of CAFOccupation objects.

        Note:
            This takes several minutes due to rate limiting (~3s per career).
            ~107 careers * 3s = ~5-6 minutes.
        """
        if careers_json_path is None:
            careers_json_path = self.output_dir / "careers_en.json"

        with open(careers_json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        careers = data.get('careers', [])
        logger.info("fetching_all_career_details", count=len(careers))

        occupations = []
        for i, career in enumerate(careers):
            slug = career.get('career_slug')
            if not slug:
                continue

            logger.info("fetching_career", index=i+1, total=len(careers), slug=slug)
            occupation = self.fetch_career_detail(slug)
            if occupation:
                occupations.append(occupation)

        logger.info("completed_fetching_careers", total=len(occupations))
        return occupations

    def save_occupations(self, occupations: list[CAFOccupation]) -> Path:
        """Save occupations to JSON file."""
        filepath = self.output_dir / "occupations.json"

        data = {
            "scraped_at": datetime.now(timezone.utc).isoformat(),
            "occupation_count": len(occupations),
            "occupations": [o.model_dump(mode="json") for o in occupations],
        }

        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)

        logger.info("saved_occupations", filepath=str(filepath), count=len(occupations))
        return filepath


def fetch_career_detail(career_slug: str, output_dir: str | Path = "data/caf") -> CAFOccupation | None:
    """Convenience function to fetch single career detail."""
    fetcher = CAFLinkFetcher(output_dir)
    return fetcher.fetch_career_detail(career_slug)
```

Update `__init__.py` to export:
```python
from .link_fetcher import CAFLinkFetcher, fetch_career_detail
```
  </action>
  <verify>
    `python -c "from jobforge.external.caf import CAFLinkFetcher, fetch_career_detail; print('Exports work')"`
    `python -c "from jobforge.external.caf.link_fetcher import CAFLinkFetcher; f = CAFLinkFetcher(); print('Instantiated')"`
  </verify>
  <done>CAFLinkFetcher created following TBS pattern with bilingual merge into single records</done>
</task>

<task type="auto">
  <name>Task 2: Fetch all career details and infer job families</name>
  <files>
    data/caf/occupations.json
    data/caf/job_families.json
    src/jobforge/external/caf/link_fetcher.py
  </files>
  <action>
1. **Run full career fetch** (this takes ~5-6 minutes due to rate limiting):
   ```python
   from jobforge.external.caf.link_fetcher import CAFLinkFetcher

   fetcher = CAFLinkFetcher()
   occupations = fetcher.fetch_all_careers()
   fetcher.save_occupations(occupations)
   ```

2. **Add job family inference** to link_fetcher.py:
   ```python
   def infer_job_families(self, occupations: list[CAFOccupation]) -> list[CAFJobFamily]:
       """Infer job families from career groupings.

       Per RESEARCH.md: forces.ca organizes by military branch, not job families.
       Use network analysis on related_careers to cluster into ~12 families.
       Also check if military_branch can serve as a proxy.
       """
       from collections import defaultdict
       from .models import CAFJobFamily

       # Group by military branch first
       branch_groups = defaultdict(list)
       for occ in occupations:
           branch = occ.military_branch or "Common"
           branch_groups[branch].append(occ)

       # Create job families from branch groups
       families = []
       family_id = 1
       for branch, careers in sorted(branch_groups.items()):
           family = CAFJobFamily(
               job_family_id=f"CAF-FAM-{family_id:02d}",
               name_en=f"{branch} Occupations",
               name_fr=None,  # Would need FR branch names
               description_en=f"CAF careers in the {branch} branch",
               career_count=len(careers),
               scraped_at=datetime.now(timezone.utc),
           )
           families.append(family)
           family_id += 1

           # Update occupations with job_family reference
           for occ in careers:
               occ.job_family = family.job_family_id

       return families

   def save_job_families(self, families: list[CAFJobFamily]) -> Path:
       """Save job families to JSON file."""
       from .models import CAFJobFamily
       filepath = self.output_dir / "job_families.json"

       data = {
           "generated_at": datetime.now(timezone.utc).isoformat(),
           "family_count": len(families),
           "families": [f.model_dump(mode="json") for f in families],
       }

       with open(filepath, 'w', encoding='utf-8') as f:
           json.dump(data, f, indent=2, ensure_ascii=False)

       logger.info("saved_job_families", filepath=str(filepath), count=len(families))
       return filepath
   ```

3. **Import CAFJobFamily** at top of link_fetcher.py:
   ```python
   from .models import CAFCareerListing, CAFOccupation, CAFProvenance, CAFJobFamily
   ```

4. **Run job family inference and save**:
   ```python
   from jobforge.external.caf.link_fetcher import CAFLinkFetcher
   import json

   fetcher = CAFLinkFetcher()

   # Load occupations if already fetched
   with open("data/caf/occupations.json", 'r') as f:
       data = json.load(f)

   from jobforge.external.caf.models import CAFOccupation
   occupations = [CAFOccupation(**o) for o in data['occupations']]

   families = fetcher.infer_job_families(occupations)
   fetcher.save_job_families(families)
   fetcher.save_occupations(occupations)  # Re-save with job_family populated
   ```
  </action>
  <verify>
    `ls -la data/caf/occupations.json` - file exists
    `ls -la data/caf/job_families.json` - file exists
    `python -c "import json; d=json.load(open('data/caf/occupations.json')); print(f'Occupations: {d[\"occupation_count\"]}')"` - shows ~107
    `python -c "import json; d=json.load(open('data/caf/job_families.json')); print(f'Families: {d[\"family_count\"]}')"` - shows expected count
  </verify>
  <done>occupations.json created with 107 careers; job_families.json created with inferred families; bilingual content in same records</done>
</task>

<task type="auto">
  <name>Task 3: Create tests for link fetcher</name>
  <files>
    tests/external/test_caf_link_fetcher.py
  </files>
  <action>
Create `tests/external/test_caf_link_fetcher.py`:

```python
"""Tests for CAF career detail fetcher."""
import json
from datetime import datetime
from pathlib import Path

import pytest

from jobforge.external.caf.models import CAFOccupation, CAFJobFamily
from jobforge.external.caf.link_fetcher import CAFLinkFetcher


class TestCAFLinkFetcher:
    """Test career detail fetching logic."""

    def test_fetcher_instantiation(self):
        """Test fetcher can be instantiated."""
        fetcher = CAFLinkFetcher()
        assert fetcher.output_dir == Path("data/caf")

    def test_url_patterns_defined(self):
        """Test URL patterns are correctly defined."""
        from jobforge.external.caf.link_fetcher import CAREER_URL_PATTERNS
        assert "en" in CAREER_URL_PATTERNS
        assert "fr" in CAREER_URL_PATTERNS
        assert "{slug}" in CAREER_URL_PATTERNS["en"]


class TestOccupationsData:
    """Tests for saved occupations data."""

    @pytest.fixture
    def occupations_data(self):
        """Load occupations.json if it exists."""
        path = Path("data/caf/occupations.json")
        if not path.exists():
            pytest.skip("occupations.json not yet generated")
        with open(path, 'r', encoding='utf-8') as f:
            return json.load(f)

    def test_occupations_count(self, occupations_data):
        """Test expected number of occupations."""
        assert occupations_data["occupation_count"] >= 50  # Expect ~107

    def test_occupations_have_bilingual_titles(self, occupations_data):
        """Test occupations have both EN and FR titles."""
        for occ in occupations_data["occupations"][:10]:
            assert occ.get("title_en"), f"Missing title_en for {occ.get('occupation_id')}"
            assert occ.get("title_fr"), f"Missing title_fr for {occ.get('occupation_id')}"

    def test_occupations_have_provenance(self, occupations_data):
        """Test occupations have provenance metadata."""
        for occ in occupations_data["occupations"][:10]:
            assert occ.get("source_url_en")
            assert occ.get("source_url_fr")
            assert occ.get("scraped_at")
            assert occ.get("content_hash_en")
            assert occ.get("content_hash_fr")

    def test_no_duplicate_rows_for_bilingual(self, occupations_data):
        """Test bilingual content in same row, not separate rows."""
        ids = [o["occupation_id"] for o in occupations_data["occupations"]]
        # No duplicates - each occupation_id appears once
        assert len(ids) == len(set(ids))


class TestJobFamiliesData:
    """Tests for saved job families data."""

    @pytest.fixture
    def families_data(self):
        """Load job_families.json if it exists."""
        path = Path("data/caf/job_families.json")
        if not path.exists():
            pytest.skip("job_families.json not yet generated")
        with open(path, 'r', encoding='utf-8') as f:
            return json.load(f)

    def test_job_families_exist(self, families_data):
        """Test job families were created."""
        assert families_data["family_count"] >= 2  # At least a few

    def test_job_families_have_ids(self, families_data):
        """Test families have proper IDs."""
        for fam in families_data["families"]:
            assert fam.get("job_family_id")
            assert fam["job_family_id"].startswith("CAF-FAM-")


@pytest.mark.integration
class TestCAFLinkFetcherIntegration:
    """Integration tests requiring network access."""

    def test_fetch_single_career(self):
        """Test fetching a single career (pilot)."""
        fetcher = CAFLinkFetcher()
        occ = fetcher.fetch_career_detail("pilot")
        assert occ is not None
        assert occ.occupation_id == "pilot"
        assert occ.title_en
        assert occ.title_fr
        assert occ.source_url_en
        assert occ.content_hash_en
```
  </action>
  <verify>
    `pytest tests/external/test_caf_link_fetcher.py -v -k "not integration"` - unit tests pass
    `pytest tests/external/test_caf_link_fetcher.py::TestOccupationsData -v` - data validation tests pass (if data exists)
  </verify>
  <done>Link fetcher tests created validating bilingual storage, provenance, and no row duplication</done>
</task>

</tasks>

<verification>
1. `python -c "from jobforge.external.caf import CAFLinkFetcher, fetch_career_detail"` - imports work
2. `pytest tests/external/test_caf_link_fetcher.py -v -k "not integration"` - unit tests pass
3. `ls -la data/caf/*.json` - occupations.json and job_families.json exist
4. `python -c "import json; d=json.load(open('data/caf/occupations.json')); print(d['occupation_count'])"` - ~107
5. `python -c "import json; d=json.load(open('data/caf/occupations.json')); o=d['occupations'][0]; print(o['title_en'], o['title_fr'])"` - bilingual
</verification>

<success_criteria>
- CAFLinkFetcher created following TBS link_fetcher pattern
- occupations.json has ~107 CAF occupations with bilingual content in same row
- Each occupation has: overview, training, requirements, related_civilian_occupations
- job_families.json has inferred job families (~3-12 depending on grouping)
- Provenance metadata on all records (source URLs, content hashes, scraped_at)
- Unit tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/15-caf-core/15-02-SUMMARY.md`
</output>
